Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14221.935376, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.6772s
model's performance on test data:
mse: 0.07997746540925973, rmse: 0.2828028737641464, mean: -0.03161622391831603
std: 0.28104408627648525, min: -0.9871538068791441, max: 0.822484291762251

iteration: 2000, loss: -4.959661, current train MSE: 0.20403456274002854, lowers train MSE: 0.1099705315291868, training time: 142.3793s
model's performance on test data:
mse: 0.015202445521829493, rmse: 0.12329819756115452, mean: -0.0598465705441604
std: 0.10780536037086974, min: -0.4518672392088279, max: 0.29603285223623743

iteration: 4000, loss: -6.333759, current train MSE: 0.08977302948950962, lowers train MSE: 0.006471641131798438, training time: 287.2481s
model's performance on test data:
mse: 0.011621174167890113, rmse: 0.10780154993268934, mean: -0.03318338292845196
std: 0.10257236168685543, min: -0.35790993394438786, max: 0.34219124305668913

iteration: 6000, loss: -9.788732, current train MSE: 0.6993354251019142, lowers train MSE: 0.0044971130317231845, training time: 440.5505s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.0005263630528697774, rmse: 0.022942603445768255, mean: -0.006063453880188863
std: 0.022127958443375683, min: -0.07382091058934748, max: 0.10680817358758077

iteration: 8000, loss: -13.161710, current train MSE: 0.001499699649096525, lowers train MSE: 0.0007084656758471126, training time: 601.7197s
model's performance on test data:
mse: 0.0004460761649372125, rmse: 0.021120515262114524, mean: -0.0010771495506192044
std: 0.021094084718731962, min: -0.050380721016665575, max: 0.10207048042752831

iteration: 10000, loss: -13.712523, current train MSE: 0.005095482245618791, lowers train MSE: 0.0004554947996427044, training time: 769.6576s
model's performance on test data:
mse: 0.0005759896255662747, rmse: 0.023999783864990843, mean: -0.00620346635225141
std: 0.023185348545227417, min: -0.06745269714457436, max: 0.07583033055209398

iteration: 12000, loss: -14.218912, current train MSE: 0.000653958058424015, lowers train MSE: 0.00037357143206680524, training time: 943.6328s
model's performance on test data:
mse: 0.00029279132230080755, rmse: 0.017111146142231606, mean: 0.0026768560726779522
std: 0.01690131147261771, min: -0.042632624148922105, max: 0.07978436679803735

iteration: 14000, loss: -14.716576, current train MSE: 0.01673519935446394, lowers train MSE: 0.00018115053531822645, training time: 1129.5397s
model's performance on test data:
mse: 0.00026197935691760395, rmse: 0.016185776376732873, mean: -0.001071527533249784
std: 0.0161510764831873, min: -0.07257908446359806, max: 0.060429285583495584

iteration: 16000, loss: -15.471660, current train MSE: 0.0003219123659450189, lowers train MSE: 0.00016587237893877035, training time: 1321.8342s
model's performance on test data:
mse: 0.00028709507744831156, rmse: 0.01694388023589377, mean: -0.001854365455332745
std: 0.01684294436493612, min: -0.051113748691093974, max: 0.08990636623121873

iteration: 18000, loss: -16.038541, current train MSE: 0.00818743761909078, lowers train MSE: 0.0001422563941769916, training time: 1520.5762s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14221.999599, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2141s
model's performance on test data:
mse: 0.07282451468408946, rmse: 0.2698601761729386, mean: -0.07259475603188474
std: 0.2599255128980995, min: -0.9648323439488049, max: 0.41985450193978124

iteration: 2000, loss: -4.677003, current train MSE: 0.43521544877887164, lowers train MSE: 0.056049095871355106, training time: 141.0431s
model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 4000, loss: -6.432277, current train MSE: 0.02444717873694466, lowers train MSE: 0.004336307977358197, training time: 287.2580s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 6000, loss: -9.366438, current train MSE: 0.015011333055649112, lowers train MSE: 0.004336307977358197, training time: 438.0270s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 8000, loss: -9.669766, current train MSE: 0.01026008619992948, lowers train MSE: 0.004336307977358197, training time: 597.9540s
model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 10000, loss: -9.786304, current train MSE: 0.008897552780004547, lowers train MSE: 0.004336307977358197, training time: 765.0007s
model's performance on test data:
mse: 0.002837386103577972, rmse: 0.05326712028613873, mean: -0.011312044152393497
std: 0.05205472823733216, min: -0.15146764588212136, max: 0.17001093622934604

iteration: 12000, loss: -10.030471, current train MSE: 0.005008660804747869, lowers train MSE: 0.003618412289360374, training time: 940.0517s
model's performance on test data:
mse: 0.0017199140687693246, rmse: 0.041471846700735726, mean: -0.008976135756618733
std: 0.04049082621271949, min: -0.13582331254778524, max: 0.09523193375895289

iteration: 14000, loss: -10.455567, current train MSE: 0.003924272847236386, lowers train MSE: 0.0019983300955017675, training time: 1125.1863s
model's performance on test data:
mse: 0.0006713866960381518, rmse: 0.025911130736387244, mean: -0.004734398046199752
std: 0.02547620606177935, min: -0.09822573218809794, max: 0.10574401025937163

iteration: 16000, loss: -10.989680, current train MSE: 0.0014641491612796742, lowers train MSE: 0.0006231391588111879, training time: 1319.0809s
model's performance on test data:
mse: 0.0005577105507548851, rmse: 0.02361589614549668, mean: -0.008313980726580978
std: 0.022105138301511684, min: -0.0774962895015392, max: 0.06839172474207089

iteration: 18000, loss: -11.396533, current train MSE: 0.0007307725464071246, lowers train MSE: 0.0002982828417365069, training time: 1519.6995s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14222.641829, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2280s
model's performance on test data:
mse: 0.0721177894297206, rmse: 0.26854755524808005, mean: -0.09068337688396645
std: 0.25278588707106286, min: -1.0181383714197345, max: 0.31341282980525875

iteration: 2000, loss: -4.007276, current train MSE: 0.5058538342114234, lowers train MSE: 0.07283074682413487, training time: 140.9293s
model's performance on test data:
mse: 0.0174257719978186, rmse: 0.13200671194230468, mean: -0.05159561345904051
std: 0.12151189733899073, min: -0.47999954933432676, max: 0.18181321812045326

iteration: 4000, loss: -6.455700, current train MSE: 1.3636884758821801, lowers train MSE: 0.005786049598776372, training time: 284.5375s
model's performance on test data:
mse: 0.004769087752225847, rmse: 0.06905858203167689, mean: -0.02539644458376246
std: 0.0642224322975273, min: -0.24731068422715374, max: 0.12433325949177743

iteration: 6000, loss: -12.006657, current train MSE: 0.29010064921981055, lowers train MSE: 0.0022271409278440497, training time: 434.7767s
model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 8000, loss: -14.304799, current train MSE: 0.0019006596080366836, lowers train MSE: 0.0003661426322641166, training time: 593.7700s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 10000, loss: -15.028456, current train MSE: 0.07231972709838622, lowers train MSE: 0.0003661426322641166, training time: 761.6738s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 12000, loss: -15.242953, current train MSE: 0.0010093807147636717, lowers train MSE: 0.0003661426322641166, training time: 934.5409s
model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 14000, loss: -15.299559, current train MSE: 0.001497393895811752, lowers train MSE: 0.0003661426322641166, training time: 1116.8288s
model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 16000, loss: -15.477245, current train MSE: 0.001499873432030675, lowers train MSE: 0.0003661426322641166, training time: 1306.3697s
model's performance on test data:
mse: 0.00035726174653401667, rmse: 0.018901368906352172, mean: -0.0017092963013385877
std: 0.01882486362401065, min: -0.04730067776949198, max: 0.052096102561080215

iteration: 18000, loss: -15.637519, current train MSE: 0.0010048306404235687, lowers train MSE: 0.00027309145609945155, training time: 1504.4239s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14229.064128, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2024s
model's performance on test data:
mse: 0.07432569649766539, rmse: 0.27262739498749095, mean: -0.06862039949551366
std: 0.2638634110924769, min: -0.9950633949010133, max: 0.6953200280859875

iteration: 2000, loss: -0.182970, current train MSE: 0.18448013634425753, lowers train MSE: 0.09752384141898529, training time: 141.7559s
model's performance on test data:
mse: 0.019407457814987168, rmse: 0.13931065219496738, mean: -0.020965704590608602
std: 0.1377308754071577, min: -0.5080477681224309, max: 0.4525011863672006

iteration: 4000, loss: -2.897478, current train MSE: 0.26300350849061266, lowers train MSE: 0.008824669186816821, training time: 287.3359s
model's performance on test data:
mse: 0.007062180493293617, rmse: 0.0840367805981025, mean: -0.017379591312255475
std: 0.08222412289054865, min: -0.3550998578945377, max: 0.1834940314269602

iteration: 6000, loss: -6.813035, current train MSE: 0.19993775680433795, lowers train MSE: 0.003971730913439449, training time: 439.1574s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 8000, loss: -10.374913, current train MSE: 0.11248973484880899, lowers train MSE: 0.0014271394396222778, training time: 599.5781s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 10000, loss: -12.049814, current train MSE: 0.004368836562248676, lowers train MSE: 0.0014271394396222778, training time: 766.7955s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 12000, loss: -12.282816, current train MSE: 0.0032038700794464374, lowers train MSE: 0.0014271394396222778, training time: 943.9770s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 14000, loss: -12.363270, current train MSE: 0.0026382073861322256, lowers train MSE: 0.0014271394396222778, training time: 1130.2368s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 16000, loss: -12.502767, current train MSE: 0.002564930387288511, lowers train MSE: 0.0014271394396222778, training time: 1325.3855s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 18000, loss: -12.686077, current train MSE: 0.004171450530313253, lowers train MSE: 0.0014271394396222778, training time: 1527.1409s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14221.935376, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2157s
model's performance on test data:
mse: 0.07997746540925973, rmse: 0.2828028737641464, mean: -0.03161622391831603
std: 0.28104408627648525, min: -0.9871538068791441, max: 0.822484291762251

iteration: 2000, loss: -4.959661, current train MSE: 0.20403456274002854, lowers train MSE: 0.1099705315291868, training time: 139.9444s
model's performance on test data:
mse: 0.015202445521829493, rmse: 0.12329819756115452, mean: -0.0598465705441604
std: 0.10780536037086974, min: -0.4518672392088279, max: 0.29603285223623743

iteration: 4000, loss: -6.333759, current train MSE: 0.08977302948950962, lowers train MSE: 0.006471641131798438, training time: 285.0525s
model's performance on test data:
mse: 0.011621174167890113, rmse: 0.10780154993268934, mean: -0.03318338292845196
std: 0.10257236168685543, min: -0.35790993394438786, max: 0.34219124305668913

iteration: 6000, loss: -9.788732, current train MSE: 0.6993354251019142, lowers train MSE: 0.0044971130317231845, training time: 434.2784s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.0005263630528697774, rmse: 0.022942603445768255, mean: -0.006063453880188863
std: 0.022127958443375683, min: -0.07382091058934748, max: 0.10680817358758077

iteration: 8000, loss: -13.161710, current train MSE: 0.001499699649096525, lowers train MSE: 0.0007084656758471126, training time: 594.1566s
model's performance on test data:
mse: 0.0004460761649372125, rmse: 0.021120515262114524, mean: -0.0010771495506192044
std: 0.021094084718731962, min: -0.050380721016665575, max: 0.10207048042752831

iteration: 10000, loss: -13.712523, current train MSE: 0.005095482245618791, lowers train MSE: 0.0004554947996427044, training time: 760.6965s
model's performance on test data:
mse: 0.0005759896255662747, rmse: 0.023999783864990843, mean: -0.00620346635225141
std: 0.023185348545227417, min: -0.06745269714457436, max: 0.07583033055209398

iteration: 12000, loss: -14.218912, current train MSE: 0.000653958058424015, lowers train MSE: 0.00037357143206680524, training time: 934.7307s
model's performance on test data:
mse: 0.00029279132230080755, rmse: 0.017111146142231606, mean: 0.0026768560726779522
std: 0.01690131147261771, min: -0.042632624148922105, max: 0.07978436679803735

iteration: 14000, loss: -14.716576, current train MSE: 0.01673519935446394, lowers train MSE: 0.00018115053531822645, training time: 1118.0835s
model's performance on test data:
mse: 0.00026197935691760395, rmse: 0.016185776376732873, mean: -0.001071527533249784
std: 0.0161510764831873, min: -0.07257908446359806, max: 0.060429285583495584

iteration: 16000, loss: -15.471660, current train MSE: 0.0003219123659450189, lowers train MSE: 0.00016587237893877035, training time: 1309.3688s
model's performance on test data:
mse: 0.00028709507744831156, rmse: 0.01694388023589377, mean: -0.001854365455332745
std: 0.01684294436493612, min: -0.051113748691093974, max: 0.08990636623121873

iteration: 18000, loss: -16.038541, current train MSE: 0.00818743761909078, lowers train MSE: 0.0001422563941769916, training time: 1508.6751s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14221.999599, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2415s
model's performance on test data:
mse: 0.07282451468408946, rmse: 0.2698601761729386, mean: -0.07259475603188474
std: 0.2599255128980995, min: -0.9648323439488049, max: 0.41985450193978124

iteration: 2000, loss: -4.677003, current train MSE: 0.43521544877887164, lowers train MSE: 0.056049095871355106, training time: 142.6759s
model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 4000, loss: -6.432277, current train MSE: 0.02444717873694466, lowers train MSE: 0.004336307977358197, training time: 287.7129s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 6000, loss: -9.366438, current train MSE: 0.015011333055649112, lowers train MSE: 0.004336307977358197, training time: 437.0400s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 8000, loss: -9.669766, current train MSE: 0.01026008619992948, lowers train MSE: 0.004336307977358197, training time: 594.7566s
model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 10000, loss: -9.786304, current train MSE: 0.008897552780004547, lowers train MSE: 0.004336307977358197, training time: 760.7381s
model's performance on test data:
mse: 0.002837386103577972, rmse: 0.05326712028613873, mean: -0.011312044152393497
std: 0.05205472823733216, min: -0.15146764588212136, max: 0.17001093622934604

iteration: 12000, loss: -10.030471, current train MSE: 0.005008660804747869, lowers train MSE: 0.003618412289360374, training time: 934.3507s
model's performance on test data:
mse: 0.0017199140687693246, rmse: 0.041471846700735726, mean: -0.008976135756618733
std: 0.04049082621271949, min: -0.13582331254778524, max: 0.09523193375895289

iteration: 14000, loss: -10.455567, current train MSE: 0.003924272847236386, lowers train MSE: 0.0019983300955017675, training time: 1117.7469s
model's performance on test data:
mse: 0.0006713866960381518, rmse: 0.025911130736387244, mean: -0.004734398046199752
std: 0.02547620606177935, min: -0.09822573218809794, max: 0.10574401025937163

iteration: 16000, loss: -10.989680, current train MSE: 0.0014641491612796742, lowers train MSE: 0.0006231391588111879, training time: 1308.3373s
model's performance on test data:
mse: 0.0005577105507548851, rmse: 0.02361589614549668, mean: -0.008313980726580978
std: 0.022105138301511684, min: -0.0774962895015392, max: 0.06839172474207089

iteration: 18000, loss: -11.396533, current train MSE: 0.0007307725464071246, lowers train MSE: 0.0002982828417365069, training time: 1506.6273s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14222.641829, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2073s
model's performance on test data:
mse: 0.0721177894297206, rmse: 0.26854755524808005, mean: -0.09068337688396645
std: 0.25278588707106286, min: -1.0181383714197345, max: 0.31341282980525875

iteration: 2000, loss: -4.007276, current train MSE: 0.5058538342114234, lowers train MSE: 0.07283074682413487, training time: 140.7813s
model's performance on test data:
mse: 0.0174257719978186, rmse: 0.13200671194230468, mean: -0.05159561345904051
std: 0.12151189733899073, min: -0.47999954933432676, max: 0.18181321812045326

iteration: 4000, loss: -6.455700, current train MSE: 1.3636884758821801, lowers train MSE: 0.005786049598776372, training time: 284.5158s
model's performance on test data:
mse: 0.004769087752225847, rmse: 0.06905858203167689, mean: -0.02539644458376246
std: 0.0642224322975273, min: -0.24731068422715374, max: 0.12433325949177743

iteration: 6000, loss: -12.006657, current train MSE: 0.29010064921981055, lowers train MSE: 0.0022271409278440497, training time: 435.8536s
model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 8000, loss: -14.304799, current train MSE: 0.0019006596080366836, lowers train MSE: 0.0003661426322641166, training time: 595.3319s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 10000, loss: -15.028456, current train MSE: 0.07231972709838622, lowers train MSE: 0.0003661426322641166, training time: 761.4101s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 12000, loss: -15.242953, current train MSE: 0.0010093807147636717, lowers train MSE: 0.0003661426322641166, training time: 936.2619s
model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 14000, loss: -15.299559, current train MSE: 0.001497393895811752, lowers train MSE: 0.0003661426322641166, training time: 1120.0811s
model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 16000, loss: -15.477245, current train MSE: 0.001499873432030675, lowers train MSE: 0.0003661426322641166, training time: 1310.7939s
model's performance on test data:
mse: 0.00035726174653401667, rmse: 0.018901368906352172, mean: -0.0017092963013385877
std: 0.01882486362401065, min: -0.04730067776949198, max: 0.052096102561080215

iteration: 18000, loss: -15.637519, current train MSE: 0.0010048306404235687, lowers train MSE: 0.00027309145609945155, training time: 1509.5367s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14229.064128, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2101s
model's performance on test data:
mse: 0.07432569649766539, rmse: 0.27262739498749095, mean: -0.06862039949551366
std: 0.2638634110924769, min: -0.9950633949010133, max: 0.6953200280859875

iteration: 2000, loss: -0.182970, current train MSE: 0.18448013634425753, lowers train MSE: 0.09752384141898529, training time: 141.9840s
model's performance on test data:
mse: 0.019407457814987168, rmse: 0.13931065219496738, mean: -0.020965704590608602
std: 0.1377308754071577, min: -0.5080477681224309, max: 0.4525011863672006

iteration: 4000, loss: -2.897478, current train MSE: 0.26300350849061266, lowers train MSE: 0.008824669186816821, training time: 287.7255s
model's performance on test data:
mse: 0.007062180493293617, rmse: 0.0840367805981025, mean: -0.017379591312255475
std: 0.08222412289054865, min: -0.3550998578945377, max: 0.1834940314269602

iteration: 6000, loss: -6.813035, current train MSE: 0.19993775680433795, lowers train MSE: 0.003971730913439449, training time: 438.7437s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 8000, loss: -10.374913, current train MSE: 0.11248973484880899, lowers train MSE: 0.0014271394396222778, training time: 599.4245s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 10000, loss: -12.049814, current train MSE: 0.004368836562248676, lowers train MSE: 0.0014271394396222778, training time: 765.9119s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 12000, loss: -12.282816, current train MSE: 0.0032038700794464374, lowers train MSE: 0.0014271394396222778, training time: 940.9387s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 14000, loss: -12.363270, current train MSE: 0.0026382073861322256, lowers train MSE: 0.0014271394396222778, training time: 1125.3156s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 16000, loss: -12.502767, current train MSE: 0.002564930387288511, lowers train MSE: 0.0014271394396222778, training time: 1316.6492s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 18000, loss: -12.686077, current train MSE: 0.004171450530313253, lowers train MSE: 0.0014271394396222778, training time: 1515.1963s
