Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14221.935376, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2501s
model's performance on test data:
mse: 0.07997746540925973, rmse: 0.2828028737641464, mean: -0.03161622391831603
std: 0.28104408627648525, min: -0.9871538068791441, max: 0.822484291762251

iteration: 2000, loss: -4.959661, current train MSE: 0.20403456274002854, lowers train MSE: 0.1099705315291868, training time: 148.0956s
model's performance on test data:
mse: 0.015202445521829493, rmse: 0.12329819756115452, mean: -0.0598465705441604
std: 0.10780536037086974, min: -0.4518672392088279, max: 0.29603285223623743

iteration: 4000, loss: -6.333759, current train MSE: 0.08977302948950962, lowers train MSE: 0.006471641131798438, training time: 300.8983s
model's performance on test data:
mse: 0.011621174167890113, rmse: 0.10780154993268934, mean: -0.03318338292845196
std: 0.10257236168685543, min: -0.35790993394438786, max: 0.34219124305668913

iteration: 6000, loss: -9.788732, current train MSE: 0.6993354251019142, lowers train MSE: 0.0044971130317231845, training time: 458.8889s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.0005263630528697774, rmse: 0.022942603445768255, mean: -0.006063453880188863
std: 0.022127958443375683, min: -0.07382091058934748, max: 0.10680817358758077

iteration: 8000, loss: -13.161710, current train MSE: 0.001499699649096525, lowers train MSE: 0.0007084656758471126, training time: 627.5156s
model's performance on test data:
mse: 0.0004460761649372125, rmse: 0.021120515262114524, mean: -0.0010771495506192044
std: 0.021094084718731962, min: -0.050380721016665575, max: 0.10207048042752831

iteration: 10000, loss: -13.712523, current train MSE: 0.005095482245618791, lowers train MSE: 0.0004554947996427044, training time: 802.2200s
model's performance on test data:
mse: 0.0005759896255662747, rmse: 0.023999783864990843, mean: -0.00620346635225141
std: 0.023185348545227417, min: -0.06745269714457436, max: 0.07583033055209398

iteration: 12000, loss: -14.218912, current train MSE: 0.000653958058424015, lowers train MSE: 0.00037357143206680524, training time: 986.9382s
model's performance on test data:
mse: 0.00029279132230080755, rmse: 0.017111146142231606, mean: 0.0026768560726779522
std: 0.01690131147261771, min: -0.042632624148922105, max: 0.07978436679803735

iteration: 14000, loss: -14.716576, current train MSE: 0.01673519935446394, lowers train MSE: 0.00018115053531822645, training time: 1179.9349s
model's performance on test data:
mse: 0.00026197935691760395, rmse: 0.016185776376732873, mean: -0.001071527533249784
std: 0.0161510764831873, min: -0.07257908446359806, max: 0.060429285583495584

iteration: 16000, loss: -15.471660, current train MSE: 0.0003219123659450189, lowers train MSE: 0.00016587237893877035, training time: 1380.3938s
model's performance on test data:
mse: 0.00028709507744831156, rmse: 0.01694388023589377, mean: -0.001854365455332745
std: 0.01684294436493612, min: -0.051113748691093974, max: 0.08990636623121873

iteration: 18000, loss: -16.038541, current train MSE: 0.00818743761909078, lowers train MSE: 0.0001422563941769916, training time: 1588.0353s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14221.999599, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2305s
model's performance on test data:
mse: 0.07282451468408946, rmse: 0.2698601761729386, mean: -0.07259475603188474
std: 0.2599255128980995, min: -0.9648323439488049, max: 0.41985450193978124

iteration: 2000, loss: -4.677003, current train MSE: 0.43521544877887164, lowers train MSE: 0.056049095871355106, training time: 150.2171s
model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 4000, loss: -6.432277, current train MSE: 0.02444717873694466, lowers train MSE: 0.004336307977358197, training time: 304.9864s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 6000, loss: -9.366438, current train MSE: 0.015011333055649112, lowers train MSE: 0.004336307977358197, training time: 465.9967s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 8000, loss: -9.669766, current train MSE: 0.01026008619992948, lowers train MSE: 0.004336307977358197, training time: 633.9156s
model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 10000, loss: -9.786304, current train MSE: 0.008897552780004547, lowers train MSE: 0.004336307977358197, training time: 809.6527s
model's performance on test data:
mse: 0.002837386103577972, rmse: 0.05326712028613873, mean: -0.011312044152393497
std: 0.05205472823733216, min: -0.15146764588212136, max: 0.17001093622934604

iteration: 12000, loss: -10.030471, current train MSE: 0.005008660804747869, lowers train MSE: 0.003618412289360374, training time: 993.8054s
model's performance on test data:
mse: 0.0017199140687693246, rmse: 0.041471846700735726, mean: -0.008976135756618733
std: 0.04049082621271949, min: -0.13582331254778524, max: 0.09523193375895289

iteration: 14000, loss: -10.455567, current train MSE: 0.003924272847236386, lowers train MSE: 0.0019983300955017675, training time: 1187.7455s
model's performance on test data:
mse: 0.0006713866960381518, rmse: 0.025911130736387244, mean: -0.004734398046199752
std: 0.02547620606177935, min: -0.09822573218809794, max: 0.10574401025937163

iteration: 16000, loss: -10.989680, current train MSE: 0.0014641491612796742, lowers train MSE: 0.0006231391588111879, training time: 1389.2305s
model's performance on test data:
mse: 0.0005577105507548851, rmse: 0.02361589614549668, mean: -0.008313980726580978
std: 0.022105138301511684, min: -0.0774962895015392, max: 0.06839172474207089

iteration: 18000, loss: -11.396533, current train MSE: 0.0007307725464071246, lowers train MSE: 0.0002982828417365069, training time: 1599.7082s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14222.641829, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2018s
model's performance on test data:
mse: 0.0721177894297206, rmse: 0.26854755524808005, mean: -0.09068337688396645
std: 0.25278588707106286, min: -1.0181383714197345, max: 0.31341282980525875

iteration: 2000, loss: -4.007276, current train MSE: 0.5058538342114234, lowers train MSE: 0.07283074682413487, training time: 149.4609s
model's performance on test data:
mse: 0.0174257719978186, rmse: 0.13200671194230468, mean: -0.05159561345904051
std: 0.12151189733899073, min: -0.47999954933432676, max: 0.18181321812045326

iteration: 4000, loss: -6.455700, current train MSE: 1.3636884758821801, lowers train MSE: 0.005786049598776372, training time: 300.2432s
model's performance on test data:
mse: 0.004769087752225847, rmse: 0.06905858203167689, mean: -0.02539644458376246
std: 0.0642224322975273, min: -0.24731068422715374, max: 0.12433325949177743

iteration: 6000, loss: -12.006657, current train MSE: 0.29010064921981055, lowers train MSE: 0.0022271409278440497, training time: 456.9983s
model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 8000, loss: -14.304799, current train MSE: 0.0019006596080366836, lowers train MSE: 0.0003661426322641166, training time: 623.4143s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 10000, loss: -15.028456, current train MSE: 0.07231972709838622, lowers train MSE: 0.0003661426322641166, training time: 797.5092s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 12000, loss: -15.242953, current train MSE: 0.0010093807147636717, lowers train MSE: 0.0003661426322641166, training time: 978.8452s
model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 14000, loss: -15.299559, current train MSE: 0.001497393895811752, lowers train MSE: 0.0003661426322641166, training time: 1171.1315s
model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 16000, loss: -15.477245, current train MSE: 0.001499873432030675, lowers train MSE: 0.0003661426322641166, training time: 1370.8540s
model's performance on test data:
mse: 0.00035726174653401667, rmse: 0.018901368906352172, mean: -0.0017092963013385877
std: 0.01882486362401065, min: -0.04730067776949198, max: 0.052096102561080215

iteration: 18000, loss: -15.637519, current train MSE: 0.0010048306404235687, lowers train MSE: 0.00027309145609945155, training time: 1577.5199s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14229.064128, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2020s
model's performance on test data:
mse: 0.07432569649766539, rmse: 0.27262739498749095, mean: -0.06862039949551366
std: 0.2638634110924769, min: -0.9950633949010133, max: 0.6953200280859875

iteration: 2000, loss: -0.182970, current train MSE: 0.18448013634425753, lowers train MSE: 0.09752384141898529, training time: 142.4562s
model's performance on test data:
mse: 0.019407457814987168, rmse: 0.13931065219496738, mean: -0.020965704590608602
std: 0.1377308754071577, min: -0.5080477681224309, max: 0.4525011863672006

iteration: 4000, loss: -2.897478, current train MSE: 0.26300350849061266, lowers train MSE: 0.008824669186816821, training time: 287.7065s
model's performance on test data:
mse: 0.007062180493293617, rmse: 0.0840367805981025, mean: -0.017379591312255475
std: 0.08222412289054865, min: -0.3550998578945377, max: 0.1834940314269602

iteration: 6000, loss: -6.813035, current train MSE: 0.19993775680433795, lowers train MSE: 0.003971730913439449, training time: 438.4918s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 8000, loss: -10.374913, current train MSE: 0.11248973484880899, lowers train MSE: 0.0014271394396222778, training time: 598.9027s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 10000, loss: -12.049814, current train MSE: 0.004368836562248676, lowers train MSE: 0.0014271394396222778, training time: 765.3592s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 12000, loss: -12.282816, current train MSE: 0.0032038700794464374, lowers train MSE: 0.0014271394396222778, training time: 938.2786s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 14000, loss: -12.363270, current train MSE: 0.0026382073861322256, lowers train MSE: 0.0014271394396222778, training time: 1121.1601s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 16000, loss: -12.502767, current train MSE: 0.002564930387288511, lowers train MSE: 0.0014271394396222778, training time: 1311.2963s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 18000, loss: -12.686077, current train MSE: 0.004171450530313253, lowers train MSE: 0.0014271394396222778, training time: 1506.8689s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14221.935376, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2125s
model's performance on test data:
mse: 0.07997746540925973, rmse: 0.2828028737641464, mean: -0.03161622391831603
std: 0.28104408627648525, min: -0.9871538068791441, max: 0.822484291762251

iteration: 2000, loss: -4.959661, current train MSE: 0.20403456274002854, lowers train MSE: 0.1099705315291868, training time: 142.2518s
model's performance on test data:
mse: 0.015202445521829493, rmse: 0.12329819756115452, mean: -0.0598465705441604
std: 0.10780536037086974, min: -0.4518672392088279, max: 0.29603285223623743

iteration: 4000, loss: -6.333759, current train MSE: 0.08977302948950962, lowers train MSE: 0.006471641131798438, training time: 287.5074s
model's performance on test data:
mse: 0.011621174167890113, rmse: 0.10780154993268934, mean: -0.03318338292845196
std: 0.10257236168685543, min: -0.35790993394438786, max: 0.34219124305668913

iteration: 6000, loss: -9.788732, current train MSE: 0.6993354251019142, lowers train MSE: 0.0044971130317231845, training time: 439.1482s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.0005263630528697774, rmse: 0.022942603445768255, mean: -0.006063453880188863
std: 0.022127958443375683, min: -0.07382091058934748, max: 0.10680817358758077

iteration: 8000, loss: -13.161710, current train MSE: 0.001499699649096525, lowers train MSE: 0.0007084656758471126, training time: 600.2963s
model's performance on test data:
mse: 0.0004460761649372125, rmse: 0.021120515262114524, mean: -0.0010771495506192044
std: 0.021094084718731962, min: -0.050380721016665575, max: 0.10207048042752831

iteration: 10000, loss: -13.712523, current train MSE: 0.005095482245618791, lowers train MSE: 0.0004554947996427044, training time: 767.4215s
model's performance on test data:
mse: 0.0005759896255662747, rmse: 0.023999783864990843, mean: -0.00620346635225141
std: 0.023185348545227417, min: -0.06745269714457436, max: 0.07583033055209398

iteration: 12000, loss: -14.218912, current train MSE: 0.000653958058424015, lowers train MSE: 0.00037357143206680524, training time: 942.3433s
model's performance on test data:
mse: 0.00029279132230080755, rmse: 0.017111146142231606, mean: 0.0026768560726779522
std: 0.01690131147261771, min: -0.042632624148922105, max: 0.07978436679803735

iteration: 14000, loss: -14.716576, current train MSE: 0.01673519935446394, lowers train MSE: 0.00018115053531822645, training time: 1127.8964s
model's performance on test data:
mse: 0.00026197935691760395, rmse: 0.016185776376732873, mean: -0.001071527533249784
std: 0.0161510764831873, min: -0.07257908446359806, max: 0.060429285583495584

iteration: 16000, loss: -15.471660, current train MSE: 0.0003219123659450189, lowers train MSE: 0.00016587237893877035, training time: 1320.2490s
model's performance on test data:
mse: 0.00028709507744831156, rmse: 0.01694388023589377, mean: -0.001854365455332745
std: 0.01684294436493612, min: -0.051113748691093974, max: 0.08990636623121873

iteration: 18000, loss: -16.038541, current train MSE: 0.00818743761909078, lowers train MSE: 0.0001422563941769916, training time: 1517.9053s
model's performance on test data:
mse: 0.00024422559289550986, rmse: 0.01562771873612748, mean: 0.003872192904805674
std: 0.015141157176764885, min: -0.050451407266564274, max: 0.09150654181513573

iteration: 20000, loss: -16.454139, current train MSE: 0.04180760782787275, lowers train MSE: 0.000107525018171096, training time: 1723.8928s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.00024422559289550986, rmse: 0.01562771873612748, mean: 0.003872192904805674
std: 0.015141157176764885, min: -0.050451407266564274, max: 0.09150654181513573

iteration: 22000, loss: -16.770316, current train MSE: 0.0002796976782547764, lowers train MSE: 0.000107525018171096, training time: 1937.9683s
2000 seconds time exceeded

model's performance on test data:
mse: 0.00024422559289550986, rmse: 0.01562771873612748, mean: 0.003872192904805674
std: 0.015141157176764885, min: -0.050451407266564274, max: 0.09150654181513573

iteration: 22570, loss: -16.784835, current train MSE: 0.0005826348513565064, lowers train MSE: 0.000107525018171096, training time: 2000.6594s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14221.999599, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2858s
model's performance on test data:
mse: 0.07282451468408946, rmse: 0.2698601761729386, mean: -0.07259475603188474
std: 0.2599255128980995, min: -0.9648323439488049, max: 0.41985450193978124

iteration: 2000, loss: -4.677003, current train MSE: 0.43521544877887164, lowers train MSE: 0.056049095871355106, training time: 143.7039s
model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 4000, loss: -6.432277, current train MSE: 0.02444717873694466, lowers train MSE: 0.004336307977358197, training time: 287.5744s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 6000, loss: -9.366438, current train MSE: 0.015011333055649112, lowers train MSE: 0.004336307977358197, training time: 436.9018s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 8000, loss: -9.669766, current train MSE: 0.01026008619992948, lowers train MSE: 0.004336307977358197, training time: 596.9921s
model's performance on test data:
mse: 0.009680400931774132, rmse: 0.09838902851321449, mean: -0.02978166909612417
std: 0.09377810276309038, min: -0.31462021786226346, max: 0.16240712368758636

iteration: 10000, loss: -9.786304, current train MSE: 0.008897552780004547, lowers train MSE: 0.004336307977358197, training time: 761.7372s
model's performance on test data:
mse: 0.002837386103577972, rmse: 0.05326712028613873, mean: -0.011312044152393497
std: 0.05205472823733216, min: -0.15146764588212136, max: 0.17001093622934604

iteration: 12000, loss: -10.030471, current train MSE: 0.005008660804747869, lowers train MSE: 0.003618412289360374, training time: 934.5917s
model's performance on test data:
mse: 0.0017199140687693246, rmse: 0.041471846700735726, mean: -0.008976135756618733
std: 0.04049082621271949, min: -0.13582331254778524, max: 0.09523193375895289

iteration: 14000, loss: -10.455567, current train MSE: 0.003924272847236386, lowers train MSE: 0.0019983300955017675, training time: 1117.6753s
model's performance on test data:
mse: 0.0006713866960381518, rmse: 0.025911130736387244, mean: -0.004734398046199752
std: 0.02547620606177935, min: -0.09822573218809794, max: 0.10574401025937163

iteration: 16000, loss: -10.989680, current train MSE: 0.0014641491612796742, lowers train MSE: 0.0006231391588111879, training time: 1307.7309s
model's performance on test data:
mse: 0.0005577105507548851, rmse: 0.02361589614549668, mean: -0.008313980726580978
std: 0.022105138301511684, min: -0.0774962895015392, max: 0.06839172474207089

iteration: 18000, loss: -11.396533, current train MSE: 0.0007307725464071246, lowers train MSE: 0.0002982828417365069, training time: 1504.7433s
model's performance on test data:
mse: 0.00018700644106194435, rmse: 0.013675029837698503, mean: 0.00013289730575009127
std: 0.013675067833810723, min: -0.03689314164516588, max: 0.0522064903861974

iteration: 20000, loss: -11.713495, current train MSE: 0.001135204527633738, lowers train MSE: 0.00013807313849052548, training time: 1708.9146s
model's performance on test data:
mse: 0.00012888241429618547, rmse: 0.01135263908948864, mean: -0.0033529661149143504
std: 0.010846741344627169, min: -0.04635916672066287, max: 0.03934513958965624

iteration: 22000, loss: -11.980364, current train MSE: 0.004221215121174821, lowers train MSE: 8.324305357486932e-05, training time: 1920.6007s
2000 seconds time exceeded

model's performance on test data:
mse: 0.00012888241429618547, rmse: 0.01135263908948864, mean: -0.0033529661149143504
std: 0.010846741344627169, min: -0.04635916672066287, max: 0.03934513958965624

iteration: 22730, loss: -12.076686, current train MSE: 0.0028275111620796206, lowers train MSE: 8.324305357486932e-05, training time: 2000.1910s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14222.641829, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2191s
model's performance on test data:
mse: 0.0721177894297206, rmse: 0.26854755524808005, mean: -0.09068337688396645
std: 0.25278588707106286, min: -1.0181383714197345, max: 0.31341282980525875

iteration: 2000, loss: -4.007276, current train MSE: 0.5058538342114234, lowers train MSE: 0.07283074682413487, training time: 138.2620s
model's performance on test data:
mse: 0.0174257719978186, rmse: 0.13200671194230468, mean: -0.05159561345904051
std: 0.12151189733899073, min: -0.47999954933432676, max: 0.18181321812045326

iteration: 4000, loss: -6.455700, current train MSE: 1.3636884758821801, lowers train MSE: 0.005786049598776372, training time: 278.9888s
model's performance on test data:
mse: 0.004769087752225847, rmse: 0.06905858203167689, mean: -0.02539644458376246
std: 0.0642224322975273, min: -0.24731068422715374, max: 0.12433325949177743

iteration: 6000, loss: -12.006657, current train MSE: 0.29010064921981055, lowers train MSE: 0.0022271409278440497, training time: 425.3173s
model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 8000, loss: -14.304799, current train MSE: 0.0019006596080366836, lowers train MSE: 0.0003661426322641166, training time: 580.9602s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 10000, loss: -15.028456, current train MSE: 0.07231972709838622, lowers train MSE: 0.0003661426322641166, training time: 743.1700s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 12000, loss: -15.242953, current train MSE: 0.0010093807147636717, lowers train MSE: 0.0003661426322641166, training time: 913.3248s
model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 14000, loss: -15.299559, current train MSE: 0.001497393895811752, lowers train MSE: 0.0003661426322641166, training time: 1090.7253s
model's performance on test data:
mse: 0.0006233503989709711, rmse: 0.024966986181174752, mean: -0.00871897811872745
std: 0.023396250946590574, min: -0.07416554989637802, max: 0.06021121010077479

iteration: 16000, loss: -15.477245, current train MSE: 0.001499873432030675, lowers train MSE: 0.0003661426322641166, training time: 1278.0445s
model's performance on test data:
mse: 0.00035726174653401667, rmse: 0.018901368906352172, mean: -0.0017092963013385877
std: 0.01882486362401065, min: -0.04730067776949198, max: 0.052096102561080215

iteration: 18000, loss: -15.637519, current train MSE: 0.0010048306404235687, lowers train MSE: 0.00027309145609945155, training time: 1471.2253s
model's performance on test data:
mse: 0.00033077974624079026, rmse: 0.018187351270616353, mean: -0.000515323430969036
std: 0.01818095825178902, min: -0.044028983573807245, max: 0.03963570079342116

iteration: 20000, loss: -15.744659, current train MSE: 0.0031741806366885955, lowers train MSE: 0.00024384369653343294, training time: 1672.8816s
model's performance on test data:
mse: 0.0002954638565975964, rmse: 0.017189062120941807, mean: 0.00032696184384216256
std: 0.01718681155418122, min: -0.04142951307341036, max: 0.08160469124129577

iteration: 22000, loss: -15.845504, current train MSE: 0.0006361274268460765, lowers train MSE: 0.00024297663325697488, training time: 1881.8643s
2000 seconds time exceeded

model's performance on test data:
mse: 0.0002954638565975964, rmse: 0.017189062120941807, mean: 0.00032696184384216256
std: 0.01718681155418122, min: -0.04142951307341036, max: 0.08160469124129577

iteration: 23100, loss: -15.897700, current train MSE: 0.0009291514140055405, lowers train MSE: 0.00024297663325697488, training time: 2000.4437s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.369792216605, rmse: 109.95167025660231, mean: 78.57621914859119
std: 76.91384241094545, min: -14.303402409409669, max: 329.67490194624423

iteration: 0, loss: 14229.064128, current train MSE: 14222.15899832589, lowers train MSE: 14222.15899832589, training time: 1.2296s
model's performance on test data:
mse: 0.07432569649766539, rmse: 0.27262739498749095, mean: -0.06862039949551366
std: 0.2638634110924769, min: -0.9950633949010133, max: 0.6953200280859875

iteration: 2000, loss: -0.182970, current train MSE: 0.18448013634425753, lowers train MSE: 0.09752384141898529, training time: 139.8086s
model's performance on test data:
mse: 0.019407457814987168, rmse: 0.13931065219496738, mean: -0.020965704590608602
std: 0.1377308754071577, min: -0.5080477681224309, max: 0.4525011863672006

iteration: 4000, loss: -2.897478, current train MSE: 0.26300350849061266, lowers train MSE: 0.008824669186816821, training time: 281.9734s
model's performance on test data:
mse: 0.007062180493293617, rmse: 0.0840367805981025, mean: -0.017379591312255475
std: 0.08222412289054865, min: -0.3550998578945377, max: 0.1834940314269602

iteration: 6000, loss: -6.813035, current train MSE: 0.19993775680433795, lowers train MSE: 0.003971730913439449, training time: 428.5823s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 8000, loss: -10.374913, current train MSE: 0.11248973484880899, lowers train MSE: 0.0014271394396222778, training time: 582.8131s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 10000, loss: -12.049814, current train MSE: 0.004368836562248676, lowers train MSE: 0.0014271394396222778, training time: 743.7558s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 12000, loss: -12.282816, current train MSE: 0.0032038700794464374, lowers train MSE: 0.0014271394396222778, training time: 912.5036s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 14000, loss: -12.363270, current train MSE: 0.0026382073861322256, lowers train MSE: 0.0014271394396222778, training time: 1093.7642s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 16000, loss: -12.502767, current train MSE: 0.002564930387288511, lowers train MSE: 0.0014271394396222778, training time: 1281.2654s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 18000, loss: -12.686077, current train MSE: 0.004171450530313253, lowers train MSE: 0.0014271394396222778, training time: 1475.3015s
model's performance on test data:
mse: 0.0021439513299142277, rmse: 0.04630282205129864, mean: -0.002676416082746165
std: 0.04622771710284895, min: -0.2072542882474977, max: 0.1398623943418329

iteration: 20000, loss: -12.879601, current train MSE: 0.0028254351109578387, lowers train MSE: 0.0014271394396222778, training time: 1676.7109s
model's performance on test data:
mse: 0.0012104911198800737, rmse: 0.034792112897610486, mean: 0.004459332265512019
std: 0.03450687683461821, min: -0.07653547248891446, max: 0.08834719709305716

iteration: 22000, loss: -13.067924, current train MSE: 0.0015645467055047165, lowers train MSE: 0.0014044419256005573, training time: 1886.6353s
2000 seconds time exceeded

model's performance on test data:
mse: 0.0013072052264671097, rmse: 0.036155293201232785, mean: -0.0029613909840084333
std: 0.03603561082195034, min: -0.08414298851511948, max: 0.09130180632348583

iteration: 23060, loss: -13.160944, current train MSE: 0.002856388362263311, lowers train MSE: 0.0013870355151535925, training time: 2001.0269s
