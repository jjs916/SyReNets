Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 37.2264795816335, rmse: 6.101350635853795, mean: 0.7079010203635189
std: 6.060447892296639, min: -10.825410765186236, max: 12.245848154161603

iteration: 0, loss: 32.350371, current train MSE: 32.51799376969983, lowers train MSE: 32.51799376969983, training time: 2.0517s
model's performance on test data:
mse: 0.14702643036637705, rmse: 0.383440256580314, mean: 0.06404111833352595
std: 0.37807335209102594, min: -0.88288188420983, max: 0.7320393383874713

iteration: 2000, loss: -8.600994, current train MSE: 0.6645560049383357, lowers train MSE: 0.1371738954413485, training time: 86.5045s
model's performance on test data:
mse: 0.13725743117506578, rmse: 0.37048270023722535, mean: 0.030298056157128498
std: 0.3692601987232533, min: -0.7945712662160442, max: 0.6789639176268576

iteration: 4000, loss: -10.224978, current train MSE: 0.200546400720942, lowers train MSE: 0.12420538309116883, training time: 174.3641s
model's performance on test data:
mse: 0.13256930213889523, rmse: 0.36410067582867134, mean: 0.0390642611734704
std: 0.3620171147262053, min: -0.7027816873188417, max: 0.6778682677759722

iteration: 6000, loss: -10.254282, current train MSE: 0.7308200905410623, lowers train MSE: 0.113028306688187, training time: 269.8496s
model's performance on test data:
mse: 0.15689388783976296, rmse: 0.39609833102370295, mean: 0.04465039985891398
std: 0.3935933450928646, min: -0.8495038623032762, max: 0.8296594667764108

iteration: 8000, loss: -10.836169, current train MSE: 0.4193012168873389, lowers train MSE: 0.11044193561490087, training time: 373.2866s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.15689388783976296, rmse: 0.39609833102370295, mean: 0.04465039985891398
std: 0.3935933450928646, min: -0.8495038623032762, max: 0.8296594667764108

iteration: 10000, loss: -11.093120, current train MSE: 0.2195004615344048, lowers train MSE: 0.11044193561490087, training time: 483.6556s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.15689388783976296, rmse: 0.39609833102370295, mean: 0.04465039985891398
std: 0.3935933450928646, min: -0.8495038623032762, max: 0.8296594667764108

iteration: 12000, loss: -11.120518, current train MSE: 0.20030727182723107, lowers train MSE: 0.11044193561490087, training time: 601.8864s
model's performance on test data:
mse: 0.15689388783976296, rmse: 0.39609833102370295, mean: 0.04465039985891398
std: 0.3935933450928646, min: -0.8495038623032762, max: 0.8296594667764108

iteration: 14000, loss: -11.127696, current train MSE: 0.196428454034125, lowers train MSE: 0.11044193561490087, training time: 730.2428s
model's performance on test data:
mse: 0.15689388783976296, rmse: 0.39609833102370295, mean: 0.04465039985891398
std: 0.3935933450928646, min: -0.8495038623032762, max: 0.8296594667764108

iteration: 16000, loss: -11.130652, current train MSE: 0.1969206527291854, lowers train MSE: 0.11044193561490087, training time: 866.2500s
model's performance on test data:
mse: 0.15689388783976296, rmse: 0.39609833102370295, mean: 0.04465039985891398
std: 0.3935933450928646, min: -0.8495038623032762, max: 0.8296594667764108

iteration: 18000, loss: -11.136163, current train MSE: 0.19480862984142086, lowers train MSE: 0.11044193561490087, training time: 1010.2751s
model's performance on test data:
mse: 0.15689388783976296, rmse: 0.39609833102370295, mean: 0.04465039985891398
std: 0.3935933450928646, min: -0.8495038623032762, max: 0.8296594667764108

iteration: 20000, loss: -11.142119, current train MSE: 0.19221259661746165, lowers train MSE: 0.11044193561490087, training time: 1162.1341s
model's performance on test data:
mse: 0.15689388783976296, rmse: 0.39609833102370295, mean: 0.04465039985891398
std: 0.3935933450928646, min: -0.8495038623032762, max: 0.8296594667764108

iteration: 22000, loss: -11.144960, current train MSE: 0.19257998758553613, lowers train MSE: 0.11044193561490087, training time: 1321.9082s
model's performance on test data:
mse: 0.15689388783976296, rmse: 0.39609833102370295, mean: 0.04465039985891398
std: 0.3935933450928646, min: -0.8495038623032762, max: 0.8296594667764108

iteration: 24000, loss: -11.141758, current train MSE: 0.19891181205294312, lowers train MSE: 0.11044193561490087, training time: 1490.7421s
model's performance on test data:
mse: 0.15689388783976296, rmse: 0.39609833102370295, mean: 0.04465039985891398
std: 0.3935933450928646, min: -0.8495038623032762, max: 0.8296594667764108

iteration: 26000, loss: -11.151280, current train MSE: 0.19244305479270807, lowers train MSE: 0.11044193561490087, training time: 1670.3631s
model's performance on test data:
mse: 0.15689388783976296, rmse: 0.39609833102370295, mean: 0.04465039985891398
std: 0.3935933450928646, min: -0.8495038623032762, max: 0.8296594667764108

iteration: 28000, loss: -11.153349, current train MSE: 0.19333986200154793, lowers train MSE: 0.11044193561490087, training time: 1857.9655s
2000 seconds time exceeded

model's performance on test data:
mse: 0.15689388783976296, rmse: 0.39609833102370295, mean: 0.04465039985891398
std: 0.3935933450928646, min: -0.8495038623032762, max: 0.8296594667764108

iteration: 29460, loss: -11.162550, current train MSE: 0.18626427596258494, lowers train MSE: 0.11044193561490087, training time: 2000.4225s
Formula: -0.003*x_1 + 0.997*x_2 + 0.019*sin(0.098*x_1) + 0.439*cos(0.098*x_1) + 0.059
model's performance on test data:
mse: 41.21020823190837, rmse: 6.419517756958724, mean: 1.6021855906526483
std: 6.21667711049327, min: -6.986474810883807, max: 16.51989773891732

iteration: 0, loss: 35.974673, current train MSE: 35.356134473681315, lowers train MSE: 35.356134473681315, training time: 0.1505s
model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 2000, loss: -9.428888, current train MSE: 0.2528557406927559, lowers train MSE: 0.11725028825849049, training time: 80.0438s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 4000, loss: -10.012796, current train MSE: 0.1715266072102286, lowers train MSE: 0.11725028825849049, training time: 165.5068s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 6000, loss: -10.056831, current train MSE: 0.18060483838247748, lowers train MSE: 0.11725028825849049, training time: 258.3633s
model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 8000, loss: -10.076687, current train MSE: 0.17993903853558066, lowers train MSE: 0.11725028825849049, training time: 359.9606s
model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 10000, loss: -10.096752, current train MSE: 0.17826394090452174, lowers train MSE: 0.11725028825849049, training time: 468.5516s
model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 12000, loss: -10.113813, current train MSE: 0.17902241054244372, lowers train MSE: 0.11725028825849049, training time: 585.0015s
model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 14000, loss: -10.131227, current train MSE: 0.1785339325085678, lowers train MSE: 0.11725028825849049, training time: 711.9492s
model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 16000, loss: -10.147471, current train MSE: 0.17886140920967536, lowers train MSE: 0.11725028825849049, training time: 846.3415s
model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 18000, loss: -10.164181, current train MSE: 0.1783508358306017, lowers train MSE: 0.11725028825849049, training time: 988.0337s
model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 20000, loss: -10.179045, current train MSE: 0.17884568447494792, lowers train MSE: 0.11725028825849049, training time: 1137.7937s
model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 22000, loss: -10.193625, current train MSE: 0.17892705884219612, lowers train MSE: 0.11725028825849049, training time: 1294.7382s
model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 24000, loss: -10.207874, current train MSE: 0.17945263486549762, lowers train MSE: 0.11725028825849049, training time: 1461.6276s
model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 26000, loss: -10.223006, current train MSE: 0.17834597084911216, lowers train MSE: 0.11725028825849049, training time: 1641.2227s
model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 28000, loss: -10.235736, current train MSE: 0.1793763142616339, lowers train MSE: 0.11725028825849049, training time: 1829.0103s
2000 seconds time exceeded

model's performance on test data:
mse: 0.1413714822632946, rmse: 0.37599399232340747, mean: 0.025197436029089196
std: 0.3751674914283381, min: -0.7135472156286262, max: 0.7245583918634608

iteration: 29720, loss: -10.248838, current train MSE: 0.17735337462034656, lowers train MSE: 0.11725028825849049, training time: 2000.5884s
Formula: 0.996*x_2 + 0.496
model's performance on test data:
mse: 34.01220965592245, rmse: 5.831998770226417, mean: 1.4251372874494328
std: 5.655474500597977, min: -9.848222242297648, max: 14.544541434536786

iteration: 0, loss: 37.479228, current train MSE: 33.90841905371404, lowers train MSE: 33.90841905371404, training time: 0.1497s
model's performance on test data:
mse: 0.1422142269257729, rmse: 0.37711301611820947, mean: 0.03612608740540701
std: 0.3753974229204009, min: -0.9136953181964067, max: 0.7131915350736406

iteration: 2000, loss: -8.859966, current train MSE: 0.7243839617872138, lowers train MSE: 0.1366311454945008, training time: 79.4729s
model's performance on test data:
mse: 0.14914563725082333, rmse: 0.3861937819939924, mean: 0.03654510619938378
std: 0.38448000604295285, min: -0.9366419961671664, max: 0.7615551157522482

iteration: 4000, loss: -9.773344, current train MSE: 0.682467572774091, lowers train MSE: 0.11495572734655621, training time: 164.4701s
model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 6000, loss: -10.215892, current train MSE: 0.6441634429385965, lowers train MSE: 0.10312822445960142, training time: 257.7101s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 8000, loss: -10.821420, current train MSE: 0.23894246079811735, lowers train MSE: 0.10312822445960142, training time: 359.5860s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 10000, loss: -10.873663, current train MSE: 0.2122452166170205, lowers train MSE: 0.10312822445960142, training time: 468.4213s
model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 12000, loss: -10.881767, current train MSE: 0.20952677369505116, lowers train MSE: 0.10312822445960142, training time: 584.5730s
model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 14000, loss: -10.891926, current train MSE: 0.20564062166206748, lowers train MSE: 0.10312822445960142, training time: 710.6857s
model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 16000, loss: -10.902563, current train MSE: 0.2013286980516833, lowers train MSE: 0.10312822445960142, training time: 845.0237s
model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 18000, loss: -10.907500, current train MSE: 0.20273659188004328, lowers train MSE: 0.10312822445960142, training time: 986.8457s
model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 20000, loss: -10.913852, current train MSE: 0.20263324058586168, lowers train MSE: 0.10312822445960142, training time: 1136.3450s
model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 22000, loss: -10.923958, current train MSE: 0.1984186519068893, lowers train MSE: 0.10312822445960142, training time: 1293.1653s
model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 24000, loss: -10.931310, current train MSE: 0.19656251787805046, lowers train MSE: 0.10312822445960142, training time: 1460.3763s
model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 26000, loss: -10.938979, current train MSE: 0.19463304447750296, lowers train MSE: 0.10312822445960142, training time: 1639.2037s
model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 28000, loss: -10.936436, current train MSE: 0.20273864796874566, lowers train MSE: 0.10312822445960142, training time: 1826.4333s
2000 seconds time exceeded

model's performance on test data:
mse: 0.13716490348137608, rmse: 0.37035780467188223, mean: -0.005999127598229459
std: 0.3703277309354658, min: -0.8618903644204998, max: 0.6653046950237211

iteration: 29790, loss: -10.934869, current train MSE: 0.20911897224456952, lowers train MSE: 0.10312822445960142, training time: 2000.6692s
Formula: 1.001*x_2 + 0.488
model's performance on test data:
mse: 42.46006636847166, rmse: 6.516138915682481, mean: 2.451205299619898
std: 6.037822827597708, min: -9.998407719366881, max: 16.805622543489708

iteration: 0, loss: 53.586433, current train MSE: 53.63012269545389, lowers train MSE: 53.63012269545389, training time: 0.1932s
model's performance on test data:
mse: 0.14615529570870425, rmse: 0.3823026232040584, mean: 0.02648903856525888
std: 0.3814029017149992, min: -0.8670428537287354, max: 0.7315015030706533

iteration: 2000, loss: -19.337202, current train MSE: 0.2328578916753279, lowers train MSE: 0.14263376745733294, training time: 141.8185s
model's performance on test data:
mse: 0.1339675572538653, rmse: 0.36601578825764514, mean: 0.007535700995506653
std: 0.36595650418031395, min: -0.7518003619857154, max: 0.6180106268146286

iteration: 4000, loss: -21.207001, current train MSE: 0.3663731759530247, lowers train MSE: 0.1317001619616997, training time: 288.1265s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.1339675572538653, rmse: 0.36601578825764514, mean: 0.007535700995506653
std: 0.36595650418031395, min: -0.7518003619857154, max: 0.6180106268146286

iteration: 6000, loss: -21.908238, current train MSE: 0.19125297410347447, lowers train MSE: 0.1317001619616997, training time: 442.1087s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.1339675572538653, rmse: 0.36601578825764514, mean: 0.007535700995506653
std: 0.36595650418031395, min: -0.7518003619857154, max: 0.6180106268146286

iteration: 8000, loss: -21.968799, current train MSE: 0.19107218062647285, lowers train MSE: 0.1317001619616997, training time: 606.3006s
model's performance on test data:
mse: 0.1339675572538653, rmse: 0.36601578825764514, mean: 0.007535700995506653
std: 0.36595650418031395, min: -0.7518003619857154, max: 0.6180106268146286

iteration: 10000, loss: -21.981371, current train MSE: 0.188644049720733, lowers train MSE: 0.1317001619616997, training time: 776.7044s
model's performance on test data:
mse: 0.1339675572538653, rmse: 0.36601578825764514, mean: 0.007535700995506653
std: 0.36595650418031395, min: -0.7518003619857154, max: 0.6180106268146286

iteration: 12000, loss: -22.000771, current train MSE: 0.18670466030759947, lowers train MSE: 0.1317001619616997, training time: 954.4274s
model's performance on test data:
mse: 0.1339675572538653, rmse: 0.36601578825764514, mean: 0.007535700995506653
std: 0.36595650418031395, min: -0.7518003619857154, max: 0.6180106268146286

iteration: 14000, loss: -22.018048, current train MSE: 0.18468108544015124, lowers train MSE: 0.1317001619616997, training time: 1142.7906s
model's performance on test data:
mse: 0.1339675572538653, rmse: 0.36601578825764514, mean: 0.007535700995506653
std: 0.36595650418031395, min: -0.7518003619857154, max: 0.6180106268146286

iteration: 16000, loss: -22.032132, current train MSE: 0.18497434554045972, lowers train MSE: 0.1317001619616997, training time: 1340.7612s
model's performance on test data:
mse: 0.1339675572538653, rmse: 0.36601578825764514, mean: 0.007535700995506653
std: 0.36595650418031395, min: -0.7518003619857154, max: 0.6180106268146286

iteration: 18000, loss: -22.045242, current train MSE: 0.18589881117666876, lowers train MSE: 0.1317001619616997, training time: 1547.2208s
model's performance on test data:
mse: 0.1339675572538653, rmse: 0.36601578825764514, mean: 0.007535700995506653
std: 0.36595650418031395, min: -0.7518003619857154, max: 0.6180106268146286

iteration: 20000, loss: -22.060473, current train MSE: 0.18377332450211598, lowers train MSE: 0.1317001619616997, training time: 1760.2520s
model's performance on test data:
mse: 0.1339675572538653, rmse: 0.36601578825764514, mean: 0.007535700995506653
std: 0.36595650418031395, min: -0.7518003619857154, max: 0.6180106268146286

iteration: 22000, loss: -22.069793, current train MSE: 0.18721787077456575, lowers train MSE: 0.1317001619616997, training time: 1980.3641s
2000 seconds time exceeded

model's performance on test data:
mse: 0.1339675572538653, rmse: 0.36601578825764514, mean: 0.007535700995506653
std: 0.36595650418031395, min: -0.7518003619857154, max: 0.6180106268146286

iteration: 22180, loss: -22.075296, current train MSE: 0.18275332745390982, lowers train MSE: 0.1317001619616997, training time: 2000.7208s
Formula: 0.997*x_2 + 0.492*cos(0.042*x_2)
model's performance on test data:
mse: 44.498663869229844, rmse: 6.670731884076128, mean: 1.8673791635850692
std: 6.404347001794734, min: -11.40360569226394, max: 17.52408479848988

iteration: 0, loss: 34.701843, current train MSE: 34.174384220539764, lowers train MSE: 34.174384220539764, training time: 0.1967s
model's performance on test data:
mse: 0.14529383597858422, rmse: 0.3811742855684053, mean: -0.0035866706780935324
std: 0.381176470204949, min: -0.7891012930802805, max: 0.6999269049335481

iteration: 2000, loss: -19.876194, current train MSE: 0.21423940713751344, lowers train MSE: 0.13140276937790313, training time: 141.1279s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.14529383597858422, rmse: 0.3811742855684053, mean: -0.0035866706780935324
std: 0.381176470204949, min: -0.7891012930802805, max: 0.6999269049335481

iteration: 4000, loss: -21.146749, current train MSE: 0.20933148299000992, lowers train MSE: 0.13140276937790313, training time: 288.8866s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.14529383597858422, rmse: 0.3811742855684053, mean: -0.0035866706780935324
std: 0.381176470204949, min: -0.7891012930802805, max: 0.6999269049335481

iteration: 6000, loss: -21.261694, current train MSE: 0.19925030098406377, lowers train MSE: 0.13140276937790313, training time: 443.5259s
model's performance on test data:
mse: 0.14529383597858422, rmse: 0.3811742855684053, mean: -0.0035866706780935324
std: 0.381176470204949, min: -0.7891012930802805, max: 0.6999269049335481

iteration: 8000, loss: -21.291692, current train MSE: 0.20013187869837054, lowers train MSE: 0.13140276937790313, training time: 606.6180s
model's performance on test data:
mse: 0.14529383597858422, rmse: 0.3811742855684053, mean: -0.0035866706780935324
std: 0.381176470204949, min: -0.7891012930802805, max: 0.6999269049335481

iteration: 10000, loss: -21.322369, current train MSE: 0.19569108048396436, lowers train MSE: 0.13140276937790313, training time: 777.1036s
model's performance on test data:
mse: 0.14529383597858422, rmse: 0.3811742855684053, mean: -0.0035866706780935324
std: 0.381176470204949, min: -0.7891012930802805, max: 0.6999269049335481

iteration: 12000, loss: -21.343810, current train MSE: 0.1971534524042317, lowers train MSE: 0.13140276937790313, training time: 955.9851s
model's performance on test data:
mse: 0.14529383597858422, rmse: 0.3811742855684053, mean: -0.0035866706780935324
std: 0.381176470204949, min: -0.7891012930802805, max: 0.6999269049335481

iteration: 14000, loss: -21.369895, current train MSE: 0.19589406835749465, lowers train MSE: 0.13140276937790313, training time: 1142.9892s
model's performance on test data:
mse: 0.14529383597858422, rmse: 0.3811742855684053, mean: -0.0035866706780935324
std: 0.381176470204949, min: -0.7891012930802805, max: 0.6999269049335481

iteration: 16000, loss: -21.390519, current train MSE: 0.1988329869673215, lowers train MSE: 0.13140276937790313, training time: 1338.4248s
model's performance on test data:
mse: 0.14529383597858422, rmse: 0.3811742855684053, mean: -0.0035866706780935324
std: 0.381176470204949, min: -0.7891012930802805, max: 0.6999269049335481

iteration: 18000, loss: -21.413341, current train MSE: 0.1988200101626677, lowers train MSE: 0.13140276937790313, training time: 1541.8373s
model's performance on test data:
mse: 0.14529383597858422, rmse: 0.3811742855684053, mean: -0.0035866706780935324
std: 0.381176470204949, min: -0.7891012930802805, max: 0.6999269049335481

iteration: 20000, loss: -21.436957, current train MSE: 0.19814852253005544, lowers train MSE: 0.13140276937790313, training time: 1753.3535s
model's performance on test data:
mse: 0.14529383597858422, rmse: 0.3811742855684053, mean: -0.0035866706780935324
std: 0.381176470204949, min: -0.7891012930802805, max: 0.6999269049335481

iteration: 22000, loss: -21.458032, current train MSE: 0.19816263083800467, lowers train MSE: 0.13140276937790313, training time: 1974.6330s
2000 seconds time exceeded

model's performance on test data:
mse: 0.14529383597858422, rmse: 0.3811742855684053, mean: -0.0035866706780935324
std: 0.381176470204949, min: -0.7891012930802805, max: 0.6999269049335481

iteration: 22230, loss: -21.467454, current train MSE: 0.19348895644460576, lowers train MSE: 0.13140276937790313, training time: 2000.9940s
Formula: 1.001*x_2 + 0.497*cos(0.019*x_2)
model's performance on test data:
mse: 40.347148717997776, rmse: 6.3519405474231085, mean: 0.8801933430559417
std: 6.290974968690838, min: -10.12815746938727, max: 16.45309539402485

iteration: 0, loss: 58.243334, current train MSE: 51.06831430894418, lowers train MSE: 51.06831430894418, training time: 0.1986s
model's performance on test data:
mse: 0.20537272060907444, rmse: 0.4531806710453066, mean: 0.21978762046833736
std: 0.39633550279253116, min: -0.890683359451419, max: 0.9993484842337046

iteration: 2000, loss: -19.120936, current train MSE: 0.5372941037332448, lowers train MSE: 0.29837367589339386, training time: 141.5620s
model's performance on test data:
mse: 0.20470942432149153, rmse: 0.4524482559602717, mean: 0.18187776047946905
std: 0.4143031129157812, min: -1.1306529631828646, max: 1.014045557705142

iteration: 4000, loss: -21.207809, current train MSE: 0.6405407435588215, lowers train MSE: 0.2633205814732525, training time: 288.9767s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.12816703726243456, rmse: 0.3580042419615088, mean: 0.04355957745034085
std: 0.3553621093682706, min: -0.6718530102863891, max: 0.6286874770956641

iteration: 6000, loss: -21.835678, current train MSE: 0.24077345593001181, lowers train MSE: 0.19902265641348774, training time: 444.8681s
model's performance on test data:
mse: 0.12776558867458934, rmse: 0.3574431264895009, mean: 0.020917482083418443
std: 0.35684840167393667, min: -0.6500536791292895, max: 0.5739899716656325

iteration: 8000, loss: -21.971423, current train MSE: 0.2404336175908064, lowers train MSE: 0.15646815244437254, training time: 608.7641s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.12776558867458934, rmse: 0.3574431264895009, mean: 0.020917482083418443
std: 0.35684840167393667, min: -0.6500536791292895, max: 0.5739899716656325

iteration: 10000, loss: -22.131664, current train MSE: 0.20666455007658924, lowers train MSE: 0.15646815244437254, training time: 779.0586s
model's performance on test data:
mse: 0.12776558867458934, rmse: 0.3574431264895009, mean: 0.020917482083418443
std: 0.35684840167393667, min: -0.6500536791292895, max: 0.5739899716656325

iteration: 12000, loss: -22.146918, current train MSE: 0.19981419886660756, lowers train MSE: 0.15646815244437254, training time: 956.6729s
model's performance on test data:
mse: 0.12776558867458934, rmse: 0.3574431264895009, mean: 0.020917482083418443
std: 0.35684840167393667, min: -0.6500536791292895, max: 0.5739899716656325

iteration: 14000, loss: -22.160670, current train MSE: 0.1987344375696, lowers train MSE: 0.15646815244437254, training time: 1144.1004s
model's performance on test data:
mse: 0.12776558867458934, rmse: 0.3574431264895009, mean: 0.020917482083418443
std: 0.35684840167393667, min: -0.6500536791292895, max: 0.5739899716656325

iteration: 16000, loss: -22.176052, current train MSE: 0.19660404160961187, lowers train MSE: 0.15646815244437254, training time: 1338.7610s
model's performance on test data:
mse: 0.12776558867458934, rmse: 0.3574431264895009, mean: 0.020917482083418443
std: 0.35684840167393667, min: -0.6500536791292895, max: 0.5739899716656325

iteration: 18000, loss: -22.188148, current train MSE: 0.19687246510248274, lowers train MSE: 0.15646815244437254, training time: 1541.3673s
model's performance on test data:
mse: 0.12776558867458934, rmse: 0.3574431264895009, mean: 0.020917482083418443
std: 0.35684840167393667, min: -0.6500536791292895, max: 0.5739899716656325

iteration: 20000, loss: -22.201542, current train MSE: 0.19600615753112643, lowers train MSE: 0.15646815244437254, training time: 1751.9338s
model's performance on test data:
mse: 0.12776558867458934, rmse: 0.3574431264895009, mean: 0.020917482083418443
std: 0.35684840167393667, min: -0.6500536791292895, max: 0.5739899716656325

iteration: 22000, loss: -22.213664, current train MSE: 0.19584747914753983, lowers train MSE: 0.15646815244437254, training time: 1970.0328s
2000 seconds time exceeded

model's performance on test data:
mse: 0.12776558867458934, rmse: 0.3574431264895009, mean: 0.020917482083418443
std: 0.35684840167393667, min: -0.6500536791292895, max: 0.5739899716656325

iteration: 22270, loss: -22.232059, current train MSE: 0.17887555916226905, lowers train MSE: 0.15646815244437254, training time: 2001.1384s
Formula: 1.001*x_2 + 0.492
