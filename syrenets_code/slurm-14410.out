Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 568752.2499316956, rmse: 754.1566481386315, mean: 23.002941394279507
std: 753.843447292422, min: -2013.7937934415181, max: 2183.8066659650317

iteration: 0, loss: 516182.691183, current train MSE: 516182.8547513611, lowers train MSE: 516182.8547513611, training time: 0.6406s
model's performance on test data:
mse: 0.38152566322731357, rmse: 0.6176776369817136, mean: -0.18084699090959286
std: 0.5906394118213953, min: -1.1219793561184588, max: 3.929039099185502

iteration: 2000, loss: 1.184431, current train MSE: 3.185440970278343, lowers train MSE: 0.25816840356053566, training time: 82.4737s
model's performance on test data:
mse: 0.2627728876143326, rmse: 0.5126137801642994, mean: -0.26460260992256374
std: 0.43906448765123, min: -1.6120645351347207, max: 1.2740018786444125

iteration: 4000, loss: -0.693747, current train MSE: 1.4212310962087866, lowers train MSE: 0.11454351941469672, training time: 167.2346s
model's performance on test data:
mse: 0.07164319123012136, rmse: 0.2676624576404419, mean: -0.022834478940941327
std: 0.26670000139097816, min: -1.2262772587919244, max: 1.4476994330166235

iteration: 6000, loss: -1.418305, current train MSE: 0.7819174182017512, lowers train MSE: 0.03259570210609522, training time: 260.2427s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.07164319123012136, rmse: 0.2676624576404419, mean: -0.022834478940941327
std: 0.26670000139097816, min: -1.2262772587919244, max: 1.4476994330166235

iteration: 8000, loss: -2.147814, current train MSE: 0.08107839014436903, lowers train MSE: 0.03259570210609522, training time: 367.4859s
model's performance on test data:
mse: 0.03828556348519334, rmse: 0.19566697085914458, mean: 0.053266687653467
std: 0.18828640065616153, min: -0.7659264303883901, max: 1.1949141830800727

iteration: 10000, loss: -1.459605, current train MSE: 0.7881583280852205, lowers train MSE: 0.01662280894548999, training time: 493.3070s
model's performance on test data:
mse: 0.02825858844494211, rmse: 0.16810291028100052, mean: 0.011119711652659764
std: 0.16774311984029971, min: -1.011638739819773, max: 0.7715966662872233

iteration: 12000, loss: -1.954949, current train MSE: 0.32904451378520694, lowers train MSE: 0.016161591605545263, training time: 627.1967s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.02825858844494211, rmse: 0.16810291028100052, mean: 0.011119711652659764
std: 0.16774311984029971, min: -1.011638739819773, max: 0.7715966662872233

iteration: 14000, loss: -2.224514, current train MSE: 0.0983854164586458, lowers train MSE: 0.016161591605545263, training time: 766.7481s
model's performance on test data:
mse: 0.02825858844494211, rmse: 0.16810291028100052, mean: 0.011119711652659764
std: 0.16774311984029971, min: -1.011638739819773, max: 0.7715966662872233

iteration: 16000, loss: -2.280195, current train MSE: 0.05390964398164325, lowers train MSE: 0.016161591605545263, training time: 900.1866s
model's performance on test data:
mse: 0.023363589669055437, rmse: 0.15285152818685013, mean: 0.04224154794954455
std: 0.14690609058783785, min: -0.46384794011169106, max: 0.5024689693568689

iteration: 18000, loss: -2.307426, current train MSE: 0.03917153971447673, lowers train MSE: 0.014693787441683337, training time: 1041.2221s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 568752.2499316956, rmse: 754.1566481386315, mean: 23.002941394279507
std: 753.843447292422, min: -2013.7937934415181, max: 2183.8066659650317

iteration: 0, loss: 516182.723072, current train MSE: 516182.8547513611, lowers train MSE: 516182.8547513611, training time: 0.6815s
model's performance on test data:
mse: 0.48843748909151075, rmse: 0.6988830296204872, mean: -0.45479171151437287
std: 0.5306883750543562, min: -1.6906155366779103, max: 2.2888346204877053

iteration: 2000, loss: 0.130501, current train MSE: 2.1076078330747072, lowers train MSE: 0.26088057165652234, training time: 81.0534s
model's performance on test data:
mse: 0.13719383875007568, rmse: 0.3703968665500232, mean: -0.04189268912016704
std: 0.3680385668318211, min: -0.6475775372525732, max: 3.1664727062398015

iteration: 4000, loss: 3.286757, current train MSE: 5.385452123448992, lowers train MSE: 0.10448175900963852, training time: 164.1015s
model's performance on test data:
mse: 0.08929889881314979, rmse: 0.2988292134533533, mean: 0.01906876795526113
std: 0.298235100848395, min: -1.5779215442908026, max: 2.3161272292873036

iteration: 6000, loss: -1.925018, current train MSE: 0.26237910977267853, lowers train MSE: 0.025906549918445782, training time: 254.6001s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.08929889881314979, rmse: 0.2988292134533533, mean: 0.01906876795526113
std: 0.298235100848395, min: -1.5779215442908026, max: 2.3161272292873036

iteration: 8000, loss: -2.108401, current train MSE: 0.12764105633772463, lowers train MSE: 0.025906549918445782, training time: 353.2090s
model's performance on test data:
mse: 0.03513721369719393, rmse: 0.18744922965217523, mean: 0.019760554183475377
std: 0.18641408005098278, min: -0.9639472045391813, max: 0.49441110426141677

iteration: 10000, loss: -1.447265, current train MSE: 0.8068008422096842, lowers train MSE: 0.020697200893798316, training time: 479.2370s
model's performance on test data:
mse: 0.03233226767135393, rmse: 0.1798117562100819, mean: 0.01364861549976074
std: 0.17930197408126003, min: -0.8543319507011802, max: 0.662590173290937

iteration: 12000, loss: -2.181374, current train MSE: 0.11227740836159397, lowers train MSE: 0.017912622933867348, training time: 597.0760s
model's performance on test data:
mse: 0.026571973612117196, rmse: 0.16300912125435557, mean: -0.02069631471593233
std: 0.16169802352627266, min: -1.0182039126725613, max: 0.8980687079033487

iteration: 14000, loss: -2.001531, current train MSE: 0.34671836210807705, lowers train MSE: 0.01542730051424468, training time: 722.4522s
model's performance on test data:
mse: 0.025766909761562772, rmse: 0.16052074558001148, mean: -0.011397126538722123
std: 0.1601236373670024, min: -1.2103296857221721, max: 0.9497135666260874

iteration: 16000, loss: -2.090006, current train MSE: 0.3219927440937317, lowers train MSE: 0.010141431532808078, training time: 864.7245s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.01936645387348339, rmse: 0.13916340709210662, mean: 0.00825485483853327
std: 0.138925308288492, min: -0.7882369978565293, max: 0.5136207597279281

iteration: 18000, loss: -2.192011, current train MSE: 0.23446860278073015, lowers train MSE: 0.009367085241017233, training time: 1012.7568s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 568752.2499316956, rmse: 754.1566481386315, mean: 23.002941394279507
std: 753.843447292422, min: -2013.7937934415181, max: 2183.8066659650317

iteration: 0, loss: 516183.041959, current train MSE: 516182.8547513611, lowers train MSE: 516182.8547513611, training time: 0.7101s
model's performance on test data:
mse: 0.38843679298360556, rmse: 0.6232469759121223, mean: -0.09308829784445702
std: 0.6162867376116312, min: -1.183521440331674, max: 3.420288855560102

iteration: 2000, loss: 1.830224, current train MSE: 3.6301510842233378, lowers train MSE: 0.2275647747185836, training time: 89.4432s
model's performance on test data:
mse: 0.1985229168878015, rmse: 0.4455591059419631, mean: -0.2392487486118706
std: 0.37589504250195577, min: -1.4059862014815394, max: 1.0677389503098311

iteration: 4000, loss: -0.330494, current train MSE: 1.5875001841505, lowers train MSE: 0.08890565776948696, training time: 183.5976s
model's performance on test data:
mse: 0.061529199493477495, rmse: 0.24805080022744835, mean: 0.027852179407765177
std: 0.24649448592376527, min: -1.4648244317345416, max: 1.1970454452557533

iteration: 6000, loss: -1.407454, current train MSE: 0.6046511519180122, lowers train MSE: 0.0334125801783909, training time: 285.4328s
model's performance on test data:
mse: 0.04266236954126405, rmse: 0.20654870985136667, mean: 0.006313654655403501
std: 0.20646251479077574, min: -1.4921794709757705, max: 0.500738863427614

iteration: 8000, loss: -0.073253, current train MSE: 2.0341039229296056, lowers train MSE: 0.019860540150435983, training time: 394.2654s
model's performance on test data:
mse: 0.02122310839397152, rmse: 0.14568153072360107, mean: 0.0358947007377258
std: 0.14119728232237855, min: -0.6425522650251878, max: 0.7140064340273966

iteration: 10000, loss: -2.111954, current train MSE: 0.09663688973094145, lowers train MSE: 0.012250529373873904, training time: 501.8258s
model's performance on test data:
mse: 0.014161686651596804, rmse: 0.11900288505576999, mean: 0.00572864318981902
std: 0.11887086412689085, min: -0.8037830301800568, max: 0.38810940677262806

iteration: 12000, loss: -2.100977, current train MSE: 0.21486725142853905, lowers train MSE: 0.009684346352668356, training time: 617.1237s
model's performance on test data:
mse: 0.009835990212846028, rmse: 0.09917656080367997, mean: 0.006505116158371064
std: 0.09896794000833509, min: -0.7267374828600168, max: 0.3100512144046661

iteration: 14000, loss: 0.523786, current train MSE: 3.3237273540062873, lowers train MSE: 0.004269291466031963, training time: 742.5903s
model's performance on test data:
mse: 0.004767588816680841, rmse: 0.06904772854106672, mean: 0.015319914938398635
std: 0.0673300999586772, min: -0.3833019649700873, max: 0.25243217623005876

iteration: 16000, loss: -3.264173, current train MSE: 0.06896467490718121, lowers train MSE: 0.0021184092920724135, training time: 874.4990s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.004767588816680841, rmse: 0.06904772854106672, mean: 0.015319914938398635
std: 0.0673300999586772, min: -0.3833019649700873, max: 0.25243217623005876

iteration: 18000, loss: -3.423861, current train MSE: 0.009775670450404454, lowers train MSE: 0.0021184092920724135, training time: 1018.9275s

##########
reduced lr to 1e-05
##########

Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 568752.2499316956, rmse: 754.1566481386315, mean: 23.002941394279507
std: 753.843447292422, min: -2013.7937934415181, max: 2183.8066659650317

iteration: 0, loss: 516186.230836, current train MSE: 516182.8547513611, lowers train MSE: 516182.8547513611, training time: 0.6797s
model's performance on test data:
mse: 0.35534472863993105, rmse: 0.596107984043102, mean: -0.09103560666643458
std: 0.5891451063576878, min: -1.2350407977343139, max: 3.162469201276508

iteration: 2000, loss: 1.865446, current train MSE: 1.8601891685411198, lowers train MSE: 0.27763930993506014, training time: 77.7620s
model's performance on test data:
mse: 0.12270595528215586, rmse: 0.3502940982690914, mean: 0.04526157022542391
std: 0.34737503157730004, min: -0.6221475840995936, max: 2.1427454493832556

iteration: 4000, loss: 3.880151, current train MSE: 4.029021718136354, lowers train MSE: 0.06476836671600097, training time: 160.1413s
model's performance on test data:
mse: 0.05853826265047768, rmse: 0.24194681781432398, mean: 0.05205528729767489
std: 0.23629238914094605, min: -0.9618571327523568, max: 0.9650162606862978

iteration: 6000, loss: 0.053207, current train MSE: 0.386086270447196, lowers train MSE: 0.03831434350790541, training time: 250.1847s
model's performance on test data:
mse: 0.05986166198854272, rmse: 0.2446664300400501, mean: 0.06563592394819084
std: 0.2357098713055762, min: -1.1064634868230314, max: 1.2813351371632962

iteration: 8000, loss: -0.574664, current train MSE: 0.11128516830154506, lowers train MSE: 0.01757803850235672, training time: 348.6824s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.01982954935952573, rmse: 0.14081743272594388, mean: 0.013147457660744061
std: 0.14020934204518154, min: -0.7600649569390043, max: 0.35152988618405345

iteration: 10000, loss: -0.679435, current train MSE: 0.12559126416426825, lowers train MSE: 0.011818614617224285, training time: 454.8022s
model's performance on test data:
mse: 0.020071820742395333, rmse: 0.14167505335236452, mean: 0.0451907307770074
std: 0.13428112953326238, min: -0.6717361669443562, max: 0.5771026371726293

iteration: 12000, loss: -0.908135, current train MSE: 0.019131822851365735, lowers train MSE: 0.008836095883034103, training time: 568.1999s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.020071820742395333, rmse: 0.14167505335236452, mean: 0.0451907307770074
std: 0.13428112953326238, min: -0.6717361669443562, max: 0.5771026371726293

iteration: 14000, loss: -0.850878, current train MSE: 0.11930539772826283, lowers train MSE: 0.008836095883034103, training time: 690.8184s
model's performance on test data:
mse: 0.013787556393686902, rmse: 0.11742042579418158, mean: 0.0346952030092976
std: 0.1121831439963311, min: -0.4075350372304456, max: 0.3768474300035507

iteration: 16000, loss: -0.945063, current train MSE: 0.07368908054609564, lowers train MSE: 0.0086463058236979, training time: 830.1214s
model's performance on test data:
mse: 0.012572842368968457, rmse: 0.11212868664605172, mean: 0.0058768276428660384
std: 0.1119801733841776, min: -0.3533497706491744, max: 0.30892283465250614

iteration: 18000, loss: -0.952799, current train MSE: 0.12239285251267726, lowers train MSE: 0.007364767280147122, training time: 984.2212s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 569876.9622394731, rmse: 754.9019553819378, mean: 23.72961219607106
std: 754.5666340611573, min: -2010.9263108850616, max: 2183.758432771088

iteration: 0, loss: 517316.691517, current train MSE: 517316.91513983003, lowers train MSE: 517316.91513983003, training time: 1.2470s
model's performance on test data:
mse: 10.537819608040747, rmse: 3.2462007960138184, mean: -0.3216862973624386
std: 3.230384045064712, min: -9.428301249041624, max: 21.20314657514291

iteration: 2000, loss: 14.219848, current train MSE: 19.385085088423445, lowers train MSE: 10.347809556492503, training time: 135.7884s
model's performance on test data:
mse: 2.38458932025467, rmse: 1.5442115529468978, mean: 0.43096809902548777
std: 1.482928092189822, min: -5.717981464082868, max: 8.706317087197931

iteration: 4000, loss: 5.197850, current train MSE: 10.566038401099068, lowers train MSE: 1.510291617070985, training time: 273.7088s
model's performance on test data:
mse: 1.2084661269813817, rmse: 1.0993025638928446, mean: 0.003982309470947449
std: 1.0993503199594357, min: -6.193911070884724, max: 5.366780067336549

iteration: 6000, loss: 5.160519, current train MSE: 10.707241873371375, lowers train MSE: 0.6035673208528942, training time: 418.2146s
model's performance on test data:
mse: 0.5055193009559684, rmse: 0.7109988051719697, mean: -0.28024068245838873
std: 0.653473154616338, min: -4.430916898857731, max: 2.10015540429049

iteration: 8000, loss: -4.428522, current train MSE: 1.3734880978480215, lowers train MSE: 0.3342740641707447, training time: 602.3219s
model's performance on test data:
mse: 0.2479759289510008, rmse: 0.4979718154183034, mean: 0.12471961471953115
std: 0.482124663537593, min: -0.8681901533068412, max: 1.4016765434909928

iteration: 10000, loss: -3.346840, current train MSE: 3.071760083182797, lowers train MSE: 0.16342153873305265, training time: 788.8178s
model's performance on test data:
mse: 0.06274219471871362, rmse: 0.2504839210782074, mean: -0.06496904799100162
std: 0.24192368685607651, min: -1.4485686173625254, max: 0.4952818778287593

iteration: 12000, loss: -7.077306, current train MSE: 0.5784289258366871, lowers train MSE: 0.040251578088616916, training time: 958.0912s
model's performance on test data:
mse: 0.04182002586210828, rmse: 0.20449945198486053, mean: -0.03421801409010868
std: 0.20162643357216972, min: -0.4799910701936625, max: 0.4161876920824312

iteration: 14000, loss: -10.131555, current train MSE: 0.20968344841294373, lowers train MSE: 0.02313620686572131, training time: 1148.6571s
model's performance on test data:
mse: 0.017866399693240168, rmse: 0.13366525237787183, mean: -0.011145062625880766
std: 0.13320646261109453, min: -0.47948579565399996, max: 0.3117019200408322

iteration: 16000, loss: -10.636187, current train MSE: 1.6683348617479674, lowers train MSE: 0.011983015675330933, training time: 1334.8317s
model's performance on test data:
mse: 0.009972965336997326, rmse: 0.09986473520215895, mean: 0.030917007420482322
std: 0.09496318126385257, min: -0.39098018863774087, max: 0.3428927428556108

iteration: 18000, loss: -13.339097, current train MSE: 0.33540488141944536, lowers train MSE: 0.006024639825210017, training time: 1540.3334s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.009972965336997326, rmse: 0.09986473520215895, mean: 0.030917007420482322
std: 0.09496318126385257, min: -0.39098018863774087, max: 0.3428927428556108

iteration: 20000, loss: -14.790551, current train MSE: 0.036635439532106615, lowers train MSE: 0.006024639825210017, training time: 1741.6228s
model's performance on test data:
mse: 0.0052746950316250865, rmse: 0.07262709571244802, mean: 0.012814395676563095
std: 0.07149124000798657, min: -0.20540355945514932, max: 0.1822499410677736

iteration: 22000, loss: -14.930848, current train MSE: 0.04536682230861903, lowers train MSE: 0.0029460359751062393, training time: 1954.6018s
2000 seconds time exceeded

model's performance on test data:
mse: 0.004548163900408375, rmse: 0.06744007636716001, mean: 0.008755765514753669
std: 0.06687262271086977, min: -0.20436859251458372, max: 0.23684413288697215

iteration: 22370, loss: -15.005860, current train MSE: 0.0049733541255079445, lowers train MSE: 0.002526707862611319, training time: 2001.0073s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 569876.9622394731, rmse: 754.9019553819378, mean: 23.72961219607106
std: 754.5666340611573, min: -2010.9263108850616, max: 2183.758432771088

iteration: 0, loss: 517316.755740, current train MSE: 517316.91513983003, lowers train MSE: 517316.91513983003, training time: 1.2508s
model's performance on test data:
mse: 7.573684835777138, rmse: 2.752032855141293, mean: -0.6466167202141009
std: 2.6751237888920185, min: -6.922762673743705, max: 17.36865968419488

iteration: 2000, loss: 13.933107, current train MSE: 19.078656477883996, lowers train MSE: 7.880737247538968, training time: 138.2246s
model's performance on test data:
mse: 2.034943564085915, rmse: 1.4265144808539152, mean: 0.0006233585316962603
std: 1.4265856761276772, min: -6.525917086767322, max: 7.287950812362851

iteration: 4000, loss: 6.867486, current train MSE: 12.20314722417407, lowers train MSE: 1.3440091333870146, training time: 279.6581s
model's performance on test data:
mse: 0.9056458067948475, rmse: 0.9516542475052836, mean: -0.17208680669165188
std: 0.9360125801289578, min: -5.201652135515587, max: 3.569705080793483

iteration: 6000, loss: 11.958477, current train MSE: 17.467517645305485, lowers train MSE: 0.6459076882359318, training time: 442.9400s
model's performance on test data:
mse: 0.49174580864267536, rmse: 0.7012458974159317, mean: -0.09716245430355042
std: 0.694516739707571, min: -3.841948482664293, max: 2.535545982610529

iteration: 8000, loss: -2.257587, current train MSE: 3.4825640099857518, lowers train MSE: 0.31216584197582325, training time: 602.7938s
model's performance on test data:
mse: 0.20905621894814513, rmse: 0.457226660364578, mean: -0.14660149016606092
std: 0.4331085088499895, min: -1.6734366884836618, max: 0.9062062310090369

iteration: 10000, loss: -4.875018, current train MSE: 1.4032103368426774, lowers train MSE: 0.12593160457513203, training time: 768.8173s
model's performance on test data:
mse: 0.08937662962713025, rmse: 0.29895924409044494, mean: 0.016138768586429812
std: 0.29853824267603096, min: -0.6327516108360669, max: 0.7546004881248791

iteration: 12000, loss: -7.428726, current train MSE: 0.1272564322628677, lowers train MSE: 0.054822312788793695, training time: 944.7783s
model's performance on test data:
mse: 0.05006305245702727, rmse: 0.22374774290934707, mean: -0.04625579528146418
std: 0.21892520803538554, min: -0.8498541940630275, max: 0.3925710765997792

iteration: 14000, loss: -9.423234, current train MSE: 0.359004745110322, lowers train MSE: 0.032301718528741, training time: 1133.8979s
model's performance on test data:
mse: 0.035842630861675606, rmse: 0.1893215013189881, mean: -0.058394095565613806
std: 0.18009998356340468, min: -0.9073181838266464, max: 0.279495745505983

iteration: 16000, loss: -12.052095, current train MSE: 0.17426376314945102, lowers train MSE: 0.016783722311569535, training time: 1326.3478s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.018384740870136602, rmse: 0.13559034209757198, mean: -0.036726254508064056
std: 0.13052826082628974, min: -0.48466855085575844, max: 0.31839225126805104

iteration: 18000, loss: -12.148724, current train MSE: 0.3415413299662558, lowers train MSE: 0.00954519775968703, training time: 1523.0197s
model's performance on test data:
mse: 0.009738390818637917, rmse: 0.09868328540658705, mean: -0.008956989676078518
std: 0.09828086829734943, min: -0.28669640011457886, max: 0.22245331461326145

iteration: 20000, loss: -12.696615, current train MSE: 0.21506599668799642, lowers train MSE: 0.007668803993309851, training time: 1727.4711s
model's performance on test data:
mse: 0.006863689382650246, rmse: 0.08284738609425313, mean: -0.009415425579727571
std: 0.08231474181383193, min: -0.3217987216853544, max: 0.38824804103569477

iteration: 22000, loss: -13.140661, current train MSE: 0.3323662309913028, lowers train MSE: 0.003639895190023162, training time: 1939.5480s
2000 seconds time exceeded

model's performance on test data:
mse: 0.006863689382650246, rmse: 0.08284738609425313, mean: -0.009415425579727571
std: 0.08231474181383193, min: -0.3217987216853544, max: 0.38824804103569477

iteration: 22560, loss: -13.599840, current train MSE: 0.0503971401706635, lowers train MSE: 0.003639895190023162, training time: 2000.8419s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 569876.9622394731, rmse: 754.9019553819378, mean: 23.72961219607106
std: 754.5666340611573, min: -2010.9263108850616, max: 2183.758432771088

iteration: 0, loss: 517317.397970, current train MSE: 517316.91513983003, lowers train MSE: 517316.91513983003, training time: 1.2575s
model's performance on test data:
mse: 10.52955929536528, rmse: 3.244928241943923, mean: -0.28090619019949675
std: 3.232908316523953, min: -5.939178585482409, max: 19.54688065951268

iteration: 2000, loss: 32.284054, current train MSE: 36.99331683385726, lowers train MSE: 11.939154703675815, training time: 159.2703s
model's performance on test data:
mse: 2.3038567079340515, rmse: 1.5178460751782612, mean: -0.40820849940688164
std: 1.4619973576557685, min: -3.6914445906922424, max: 7.915211681838173

iteration: 4000, loss: 7.193986, current train MSE: 11.97339483536092, lowers train MSE: 1.594394498748181, training time: 326.5936s
model's performance on test data:
mse: 1.1463651680975946, rmse: 1.0706844390844552, mean: 0.07612182684285515
std: 1.0680284194144376, min: -2.385398635741012, max: 4.716831490497043

iteration: 6000, loss: 7.590454, current train MSE: 12.593652857665528, lowers train MSE: 0.6767239988510774, training time: 474.5609s
model's performance on test data:
mse: 0.37930848133053113, rmse: 0.6158802491804158, mean: 0.18545887049833237
std: 0.5873227252993121, min: -1.2241170485080772, max: 3.3746403148647914

iteration: 8000, loss: 10.983202, current train MSE: 16.22903030765315, lowers train MSE: 0.36860865589722136, training time: 631.9499s
model's performance on test data:
mse: 0.2165549646959633, rmse: 0.46535466549285104, mean: -0.10410629166626628
std: 0.45358286850506074, min: -2.3934125066878096, max: 2.4482808453030884

iteration: 10000, loss: -5.106101, current train MSE: 0.6247041413411918, lowers train MSE: 0.10045548115790828, training time: 800.0452s
model's performance on test data:
mse: 0.048404827022404805, rmse: 0.22001097023195185, mean: 0.019939144282127435
std: 0.21911654154608703, min: -0.6889171008392623, max: 0.7583790547371336

iteration: 12000, loss: -5.726354, current train MSE: 1.2444811033601915, lowers train MSE: 0.038888956368304306, training time: 972.4765s
model's performance on test data:
mse: 0.013851583447589223, rmse: 0.11769275019128929, mean: 0.005432670316261848
std: 0.11757317676486154, min: -0.3753027897009815, max: 0.240592636451197

iteration: 14000, loss: -9.169876, current train MSE: 0.12700306180063137, lowers train MSE: 0.008341640252297892, training time: 1162.2403s
model's performance on test data:
mse: 0.0071695925228754875, rmse: 0.08467344638595672, mean: 0.011457690747154817
std: 0.08389885429251617, min: -0.33739452554118543, max: 0.20816072435263777

iteration: 16000, loss: -11.798335, current train MSE: 0.029261936287634162, lowers train MSE: 0.006059747412080638, training time: 1361.9014s
model's performance on test data:
mse: 0.003199832477836535, rmse: 0.05656706177482206, mean: 0.012925542344531858
std: 0.05507327974300534, min: -0.2636935058110339, max: 0.48088492716215114

iteration: 18000, loss: -13.050014, current train MSE: 0.034013271139814824, lowers train MSE: 0.002827430897531019, training time: 1558.9690s
model's performance on test data:
mse: 0.004007677948363465, rmse: 0.0633062236147716, mean: 0.01979907254289329
std: 0.06013348718565582, min: -0.1656061318924884, max: 0.5942507451200072

iteration: 20000, loss: -14.327495, current train MSE: 0.3796665020898205, lowers train MSE: 0.002789831436133298, training time: 1773.4710s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.004365699909067028, rmse: 0.06607344329658496, mean: 0.022654202285938823
std: 0.06207150970661705, min: -0.1589079774644233, max: 0.24714369895445998

iteration: 22000, loss: -14.848726, current train MSE: 0.16862456119215777, lowers train MSE: 0.002375863599711848, training time: 1991.5526s
2000 seconds time exceeded

model's performance on test data:
mse: 0.004365699909067028, rmse: 0.06607344329658496, mean: 0.022654202285938823
std: 0.06207150970661705, min: -0.1589079774644233, max: 0.24714369895445998

iteration: 22070, loss: -15.010650, current train MSE: 0.011540851043386919, lowers train MSE: 0.002375863599711848, training time: 2001.0599s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 569876.9622394731, rmse: 754.9019553819378, mean: 23.72961219607106
std: 754.5666340611573, min: -2010.9263108850616, max: 2183.758432771088

iteration: 0, loss: 517323.820270, current train MSE: 517316.91513983003, lowers train MSE: 517316.91513983003, training time: 1.2643s
model's performance on test data:
mse: 10.317132336411834, rmse: 3.2120293174894643, mean: -0.9456253113627665
std: 3.0698318355782095, min: -7.971061828298275, max: 12.444515983427664

iteration: 2000, loss: 41.332715, current train MSE: 42.14209061696907, lowers train MSE: 10.048645134839319, training time: 138.7425s
model's performance on test data:
mse: 1.392410653740171, rmse: 1.1800045142880475, mean: 0.11289741503946021
std: 1.1746500792038788, min: -5.439612696744689, max: 6.628437471383677

iteration: 4000, loss: 7.882958, current train MSE: 9.01348742807319, lowers train MSE: 0.7565159718307589, training time: 278.8704s
model's performance on test data:
mse: 0.6163076893682492, rmse: 0.7850526666206855, mean: -0.0420215663106132
std: 0.7839664138382654, min: -6.131831822461436, max: 3.458917377002763

iteration: 6000, loss: 16.518673, current train MSE: 17.89361307241945, lowers train MSE: 0.3340704667375425, training time: 427.6891s
model's performance on test data:
mse: 0.189283468012453, rmse: 0.43506719942148364, mean: 0.014959471202819152
std: 0.43483168031183467, min: -2.984777291207365, max: 2.2750664054315166

iteration: 8000, loss: -1.079608, current train MSE: 0.6587142448527861, lowers train MSE: 0.18600779309842547, training time: 584.8094s
model's performance on test data:
mse: 0.09707473999182266, rmse: 0.3115681947693356, mean: 0.05429088214946279
std: 0.3068169712207121, min: -1.6056768529845158, max: 1.5695499987973562

iteration: 10000, loss: -2.151661, current train MSE: 0.07796390440746502, lowers train MSE: 0.07796390440746502, training time: 748.9923s
model's performance on test data:
mse: 0.046787891398954416, rmse: 0.2163050887033276, mean: -0.026304930087294374
std: 0.21471039131218903, min: -1.4918871039023998, max: 1.4158646807045443

iteration: 12000, loss: -2.739419, current train MSE: 0.5831999022682789, lowers train MSE: 0.03391057830678973, training time: 920.3574s
model's performance on test data:
mse: 0.019311902255997722, rmse: 0.13896727044882806, mean: -0.03757768991338622
std: 0.13379689700975295, min: -0.6856942102479024, max: 0.9005751752424658

iteration: 14000, loss: -4.607494, current train MSE: 0.47025829168225364, lowers train MSE: 0.015116492006087385, training time: 1102.7838s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.021558495118034076, rmse: 0.14682811419491185, mean: -0.0728444844718144
std: 0.12749039802890186, min: -0.6818290695787255, max: 0.20274628235893033

iteration: 16000, loss: -5.416550, current train MSE: 0.26199618307749184, lowers train MSE: 0.009873709237415797, training time: 1292.3661s
model's performance on test data:
mse: 0.010655396583241904, rmse: 0.10322498042257941, mean: -0.00748164546304401
std: 0.10295864033108164, min: -0.5154827090198069, max: 0.40175010329448924

iteration: 18000, loss: -6.057424, current train MSE: 0.04665680687880919, lowers train MSE: 0.008263979314383484, training time: 1495.0361s
model's performance on test data:
mse: 0.007915223637565196, rmse: 0.08896754260720702, mean: -0.0041250517957082435
std: 0.08887630443450072, min: -0.4475620819243886, max: 0.560171759572313

iteration: 20000, loss: -6.086545, current train MSE: 0.7383518091667917, lowers train MSE: 0.005520592130282367, training time: 1713.1544s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 0.007915223637565196, rmse: 0.08896754260720702, mean: -0.0041250517957082435
std: 0.08887630443450072, min: -0.4475620819243886, max: 0.560171759572313

iteration: 22000, loss: -7.817012, current train MSE: 0.03395054684129476, lowers train MSE: 0.005520592130282367, training time: 1938.0254s
2000 seconds time exceeded

model's performance on test data:
mse: 0.007915223637565196, rmse: 0.08896754260720702, mean: -0.0041250517957082435
std: 0.08887630443450072, min: -0.4475620819243886, max: 0.560171759572313

iteration: 22490, loss: -7.836677, current train MSE: 0.03705835979481868, lowers train MSE: 0.005520592130282367, training time: 2000.3521s
