Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.961457113606, rmse: 109.95436079171033, mean: 78.57875312786895
std: 76.91510002083797, min: -14.305151613357426, max: 329.6784846191232

iteration: 0, loss: 9437.801400, current train MSE: 9437.98963752708, lowers train MSE: 9437.98963752708, training time: 1.8472s
model's performance on test data:
mse: 0.1322238991294814, rmse: 0.36362604297475914, mean: 0.11497713563772416
std: 0.34498704191334884, min: -1.230407667931388, max: 1.6554460568947178

iteration: 2000, loss: -5.849235, current train MSE: 0.9866531474678746, lowers train MSE: 0.11778878190420197, training time: 142.1077s
model's performance on test data:
mse: 0.01585561476476602, rmse: 0.1259190802252225, mean: 0.0028042456450841236
std: 0.1258941456737069, min: -0.6091954183220878, max: 0.37731159871803754

iteration: 4000, loss: -9.856599, current train MSE: 0.16025775559650757, lowers train MSE: 0.010646626243672533, training time: 285.8541s
model's performance on test data:
mse: 0.002214803905530186, rmse: 0.047061703172857926, mean: -0.00521473380436313
std: 0.0467742369391454, min: -0.1653431391512754, max: 0.19229107716454052

iteration: 6000, loss: -13.428093, current train MSE: 0.029243791678279202, lowers train MSE: 0.0016001236487868681, training time: 435.6035s
model's performance on test data:
mse: 0.0010023931135547247, rmse: 0.031660592438467174, mean: 0.007281778186279127
std: 0.03081336994001184, min: -0.07669628965319575, max: 0.10615194909431125

iteration: 8000, loss: -16.477816, current train MSE: 0.003367725334571363, lowers train MSE: 0.0006647558345493085, training time: 594.7096s
model's performance on test data:
mse: 0.00030123654667456594, rmse: 0.017356167395901838, mean: 0.001401753140351209
std: 0.01730033425025953, min: -0.057406033729932915, max: 0.054716197657995735

iteration: 10000, loss: -17.383070, current train MSE: 0.003176974132120068, lowers train MSE: 0.00022437503431627922, training time: 758.5825s
model's performance on test data:
mse: 0.00014658222774102973, rmse: 0.01210711475707692, mean: -0.0024503413348619307
std: 0.0118571545656688, min: -0.03487579968489918, max: 0.09775987542059283

iteration: 12000, loss: -18.958157, current train MSE: 0.0010439815410491038, lowers train MSE: 7.552971918131594e-05, training time: 930.8580s
model's performance on test data:
mse: 2.028631308304443e-05, rmse: 0.0045040329797909374, mean: 0.0008976650178052158
std: 0.004413893843173616, min: -0.009701849832715936, max: 0.012816466064454524

iteration: 14000, loss: -19.371137, current train MSE: 4.4120456440621225e-05, lowers train MSE: 1.6306810124556542e-05, training time: 1113.2804s
model's performance on test data:
mse: 1.9849554122112655e-05, rmse: 0.004455283843046665, mean: 0.0005534621651733108
std: 0.004420994038156615, min: -0.010992890031765512, max: 0.011575535175552432

iteration: 16000, loss: -19.611620, current train MSE: 0.0002570161631567263, lowers train MSE: 1.5779436163109105e-05, training time: 1302.6526s
model's performance on test data:
mse: 2.2453427994530153e-05, rmse: 0.0047385048268974205, mean: 0.0013412292234371709
std: 0.00454495300738031, min: -0.009197428334729807, max: 0.013423770163719873

iteration: 18000, loss: -19.828205, current train MSE: 0.0002352694279841868, lowers train MSE: 9.742030540271517e-06, training time: 1500.4643s

##########
reduced lr to 0.0001
##########

Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.961457113606, rmse: 109.95436079171033, mean: 78.57875312786895
std: 76.91510002083797, min: -14.305151613357426, max: 329.6784846191232

iteration: 0, loss: 9437.865653, current train MSE: 9437.98963752708, lowers train MSE: 9437.98963752708, training time: 1.1944s
model's performance on test data:
mse: 0.15015620424129425, rmse: 0.3874999409565042, mean: 0.18230015012178155
std: 0.34195694617924577, min: -0.6491121591857052, max: 0.9103731128886352

iteration: 2000, loss: -6.673842, current train MSE: 0.22441392934011567, lowers train MSE: 0.07633456625164403, training time: 136.9705s
model's performance on test data:
mse: 0.007984020257357515, rmse: 0.08935334497016614, mean: 0.02200353317854667
std: 0.08660609015207713, min: -0.2871368410163768, max: 0.4959877529400245

iteration: 4000, loss: -9.963576, current train MSE: 0.13277248239499007, lowers train MSE: 0.004694189374576362, training time: 278.2720s
model's performance on test data:
mse: 0.005419252120410053, rmse: 0.07361556982330608, mean: 0.02311523828423688
std: 0.06989582552119386, min: -0.1607104070877199, max: 0.4066888604613865

iteration: 6000, loss: -13.190861, current train MSE: 0.06553678066234932, lowers train MSE: 0.0024325880792868165, training time: 425.2127s
model's performance on test data:
mse: 0.0012076342384440848, rmse: 0.034751032192498754, mean: 0.00760294630737492
std: 0.03391083073438694, min: -0.11318954793080138, max: 0.1888444683799264

iteration: 8000, loss: -16.451815, current train MSE: 0.01789066725236275, lowers train MSE: 0.0006813376113851948, training time: 581.1546s
model's performance on test data:
mse: 0.000490080982866466, rmse: 0.022137772762102017, mean: 0.005762949513917201
std: 0.02137557221556841, min: -0.09344779527037872, max: 0.07550067199854027

iteration: 10000, loss: -17.354732, current train MSE: 0.004620589347686305, lowers train MSE: 0.00041351399614888485, training time: 743.8198s
model's performance on test data:
mse: 6.0844327196568175e-05, rmse: 0.007800277379463385, mean: 0.0012341220401893126
std: 0.007702415383525327, min: -0.021266415036620856, max: 0.03728265975578893

iteration: 12000, loss: -18.968808, current train MSE: 0.0008288411591715955, lowers train MSE: 3.766465424856684e-05, training time: 915.7235s
model's performance on test data:
mse: 2.143740215813688e-05, rmse: 0.004630054228422911, mean: -0.00041450013605258233
std: 0.004611693678235371, min: -0.013033816232551843, max: 0.015504087962384006

iteration: 14000, loss: -19.334909, current train MSE: 0.0005549300820808031, lowers train MSE: 1.719369542046129e-05, training time: 1096.6715s
model's performance on test data:
mse: 2.7518629090893632e-05, rmse: 0.005245820154265073, mean: 0.0029865721896891262
std: 0.004312873258808873, min: -0.007428708069397771, max: 0.01787721841584755

iteration: 16000, loss: -19.602616, current train MSE: 0.001827742112369936, lowers train MSE: 1.479029900984869e-05, training time: 1284.5109s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 2.7518629090893632e-05, rmse: 0.005245820154265073, mean: 0.0029865721896891262
std: 0.004312873258808873, min: -0.007428708069397771, max: 0.01787721841584755

iteration: 18000, loss: -19.769034, current train MSE: 0.00013926934531363852, lowers train MSE: 1.479029900984869e-05, training time: 1479.4179s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.961457113606, rmse: 109.95436079171033, mean: 78.57875312786895
std: 76.91510002083797, min: -14.305151613357426, max: 329.6784846191232

iteration: 0, loss: 9438.508177, current train MSE: 9437.98963752708, lowers train MSE: 9437.98963752708, training time: 1.2024s
model's performance on test data:
mse: 0.16192738669758894, rmse: 0.40240202123944274, mean: 0.10916296018601057
std: 0.38733168925540673, min: -0.8477077448852128, max: 1.668683202656979

iteration: 2000, loss: -5.605138, current train MSE: 0.42751685256660915, lowers train MSE: 0.11621155648313478, training time: 136.9574s
model's performance on test data:
mse: 0.021645007729665506, rmse: 0.14712242429237463, mean: -0.02227270317581797
std: 0.1454340040718556, min: -0.7481386409564266, max: 0.5570458294960048

iteration: 4000, loss: -8.776386, current train MSE: 0.38864853742600936, lowers train MSE: 0.013148070471468066, training time: 278.5644s
model's performance on test data:
mse: 0.004891408207215925, rmse: 0.06993860312599848, mean: 0.011314348722485695
std: 0.0690207947680062, min: -0.22155468419146018, max: 0.36323956920406886

iteration: 6000, loss: -13.906032, current train MSE: 0.006667034287658233, lowers train MSE: 0.0041526132411776225, training time: 425.8767s
model's performance on test data:
mse: 0.0025172629312634905, rmse: 0.05017233232832106, mean: 0.027847389572372802
std: 0.04173679458928739, min: -0.08582176473652225, max: 0.2619558463497498

iteration: 8000, loss: -16.339974, current train MSE: 0.00231428352816184, lowers train MSE: 0.0015680467432805658, training time: 581.5768s
model's performance on test data:
mse: 0.0007512695241384388, rmse: 0.027409296308705897, mean: 0.007981088685676575
std: 0.02622290052851047, min: -0.07006281594303765, max: 0.09427312222362616

iteration: 10000, loss: -17.166913, current train MSE: 0.0011074439734811814, lowers train MSE: 0.000662652116401205, training time: 743.8093s
model's performance on test data:
mse: 6.267217130978522e-05, rmse: 0.007916575731323816, mean: -0.001537982521564316
std: 0.007766132395756618, min: -0.02165078008766841, max: 0.0180457199314219

iteration: 12000, loss: -18.838125, current train MSE: 0.00025235635661813354, lowers train MSE: 7.925945382809019e-05, training time: 914.3441s
model's performance on test data:
mse: 3.022629302057728e-05, rmse: 0.005497844397632338, mean: -0.00035626831709374067
std: 0.005486563238195715, min: -0.013201847821690649, max: 0.01047782424335253

iteration: 14000, loss: -19.253654, current train MSE: 0.0002851970185063595, lowers train MSE: 1.7543440337861197e-05, training time: 1094.2718s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 3.022629302057728e-05, rmse: 0.005497844397632338, mean: -0.00035626831709374067
std: 0.005486563238195715, min: -0.013201847821690649, max: 0.01047782424335253

iteration: 16000, loss: -19.467593, current train MSE: 0.00024633401406344417, lowers train MSE: 1.7543440337861197e-05, training time: 1282.4844s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 3.022629302057728e-05, rmse: 0.005497844397632338, mean: -0.00035626831709374067
std: 0.005486563238195715, min: -0.013201847821690649, max: 0.01047782424335253

iteration: 18000, loss: -19.490768, current train MSE: 0.00010636550344228735, lowers train MSE: 1.7543440337861197e-05, training time: 1476.3262s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12089.961457113606, rmse: 109.95436079171033, mean: 78.57875312786895
std: 76.91510002083797, min: -14.305151613357426, max: 329.6784846191232

iteration: 0, loss: 9444.933417, current train MSE: 9437.98963752708, lowers train MSE: 9437.98963752708, training time: 1.2026s
model's performance on test data:
mse: 0.3458796509210465, rmse: 0.588115338110686, mean: 0.2753969633902063
std: 0.5196760240900964, min: -1.3142575106640244, max: 1.5673808834976768

iteration: 2000, loss: 0.133077, current train MSE: 2.590087386530196, lowers train MSE: 0.30394019076267376, training time: 141.6383s
model's performance on test data:
mse: 0.05415919876577077, rmse: 0.23272128988506996, mean: 0.06738415379899136
std: 0.22276341029034652, min: -0.47287896459303624, max: 0.5610973282992973

iteration: 4000, loss: -7.349365, current train MSE: 0.20421646648196096, lowers train MSE: 0.03339809459874688, training time: 285.5359s
model's performance on test data:
mse: 0.0034403931862957756, rmse: 0.058654864984038414, mean: 0.03282482154215114
std: 0.04861235022469256, min: -0.17125626625482937, max: 0.26120336880707384

iteration: 6000, loss: -11.006192, current train MSE: 0.007589827898576981, lowers train MSE: 0.0019776504791959217, training time: 436.9508s
model's performance on test data:
mse: 0.0004394191921949872, rmse: 0.020962327928810465, mean: 0.002426402240971167
std: 0.020822466764545088, min: -0.05010795828793135, max: 0.04768413607735056

iteration: 8000, loss: -13.406789, current train MSE: 0.004656216514805357, lowers train MSE: 0.00034135363499781884, training time: 596.5773s
model's performance on test data:
mse: 9.015624703053457e-05, rmse: 0.00949506435104758, mean: -0.001261306840354782
std: 0.009411387228149897, min: -0.025039833601681494, max: 0.024642473506702345

iteration: 10000, loss: -15.853523, current train MSE: 0.0013744574701334226, lowers train MSE: 6.814570739962972e-05, training time: 760.9189s
model's performance on test data:
mse: 3.2433742472985104e-05, rmse: 0.005695062991134084, mean: 0.00043775892066346675
std: 0.005678497525977789, min: -0.013509476967740852, max: 0.01788082299179905

iteration: 12000, loss: -17.057677, current train MSE: 0.11468360398785471, lowers train MSE: 1.9650800797906414e-05, training time: 934.9960s
model's performance on test data:
mse: 3.5041597782304436e-05, rmse: 0.005919594393394233, mean: -0.0020475927883273543
std: 0.005554461880514415, min: -0.014880877265710524, max: 0.01052901085060931

iteration: 14000, loss: -18.229206, current train MSE: 0.03473989471524515, lowers train MSE: 1.8529657693673938e-05, training time: 1118.8976s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 2.4944500110337925e-05, rmse: 0.004994446927372232, mean: 0.0009202707915043615
std: 0.004909176284771192, min: -0.009511088376314092, max: 0.012626655140451248

iteration: 16000, loss: -18.862030, current train MSE: 0.00014364331453547386, lowers train MSE: 1.7049805387059025e-05, training time: 1308.3257s
model's performance on test data:
mse: 3.40544087100885e-05, rmse: 0.005835615538234891, mean: -0.00046077604994162677
std: 0.005817686715103307, min: -0.01893997298387262, max: 0.0156098120058914

iteration: 18000, loss: -19.074248, current train MSE: 0.0012774030709914465, lowers train MSE: 1.0108149190595281e-05, training time: 1504.9707s

##########
reduced lr to 1e-05
##########

Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12087.434869096402, rmse: 109.94287093348255, mean: 78.5647786413714
std: 76.91295073197045, min: -14.258862147461935, max: 329.6462746417389

iteration: 0, loss: 6838.417550, current train MSE: 6838.629584570506, lowers train MSE: 6838.629584570506, training time: 1.2196s
model's performance on test data:
mse: 0.2799032096681094, rmse: 0.5290587960407703, mean: -0.05605982899612366
std: 0.5261066282179493, min: -1.0492219101192717, max: 2.8620728874248016

iteration: 2000, loss: -4.149732, current train MSE: 0.4054989885029171, lowers train MSE: 0.39001538650888745, training time: 143.7356s
model's performance on test data:
mse: 0.019816158377610606, rmse: 0.14076987738010788, mean: -0.03762839232626762
std: 0.13565435006970547, min: -0.4789234329669654, max: 0.2694246207177571

iteration: 4000, loss: -6.782646, current train MSE: 0.21596704821830903, lowers train MSE: 0.017476338812000784, training time: 287.0053s
model's performance on test data:
mse: 0.006988393703481662, rmse: 0.0835966129904894, mean: -0.040807295107759045
std: 0.07296362615143319, min: -0.3650759111870059, max: 0.05174914105879225

iteration: 6000, loss: -13.470504, current train MSE: 0.05138677489658505, lowers train MSE: 0.0020517878797846065, training time: 435.2173s
model's performance on test data:
mse: 0.0011849015236994292, rmse: 0.034422398575628475, mean: 0.009222636225386441
std: 0.03316556197318719, min: -0.10012812867289966, max: 0.06504036628327015

iteration: 8000, loss: -16.813666, current train MSE: 0.012634940219853655, lowers train MSE: 0.000921627313426397, training time: 591.4760s
model's performance on test data:
mse: 0.0002393921862706129, rmse: 0.015472303844955118, mean: 0.005585255939842862
std: 0.014429758288918564, min: -0.03890358406715677, max: 0.03273936821426293

iteration: 10000, loss: -19.171055, current train MSE: 0.003163824668278032, lowers train MSE: 0.00017377622983737274, training time: 754.6909s
model's performance on test data:
mse: 9.549240004413305e-05, rmse: 0.009772021287539904, mean: 0.0024975154754024865
std: 0.009447949138605189, min: -0.0328409136949972, max: 0.019959374546587583

iteration: 12000, loss: -20.020105, current train MSE: 0.0004707733731701091, lowers train MSE: 6.172902799847969e-05, training time: 927.5133s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 9.549240004413305e-05, rmse: 0.009772021287539904, mean: 0.0024975154754024865
std: 0.009447949138605189, min: -0.0328409136949972, max: 0.019959374546587583

iteration: 14000, loss: -20.527589, current train MSE: 0.009230742257601574, lowers train MSE: 6.172902799847969e-05, training time: 1108.9135s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 9.549240004413305e-05, rmse: 0.009772021287539904, mean: 0.0024975154754024865
std: 0.009447949138605189, min: -0.0328409136949972, max: 0.019959374546587583

iteration: 16000, loss: -20.610285, current train MSE: 0.00040779343224099673, lowers train MSE: 6.172902799847969e-05, training time: 1297.7367s
model's performance on test data:
mse: 9.549240004413305e-05, rmse: 0.009772021287539904, mean: 0.0024975154754024865
std: 0.009447949138605189, min: -0.0328409136949972, max: 0.019959374546587583

iteration: 18000, loss: -20.629090, current train MSE: 0.0004347910465200499, lowers train MSE: 6.172902799847969e-05, training time: 1494.2227s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12087.434869096402, rmse: 109.94287093348255, mean: 78.5647786413714
std: 76.91295073197045, min: -14.258862147461935, max: 329.6462746417389

iteration: 0, loss: 6838.481770, current train MSE: 6838.629584570506, lowers train MSE: 6838.629584570506, training time: 1.2159s
model's performance on test data:
mse: 0.29459983652570954, rmse: 0.5427705192120419, mean: -0.07297199638838515
std: 0.5378697378182332, min: -1.0968176119177464, max: 2.95306248438942

iteration: 2000, loss: -3.980379, current train MSE: 0.5207200590501819, lowers train MSE: 0.4161676972222723, training time: 141.1560s
model's performance on test data:
mse: 0.02166338006731688, rmse: 0.1471848499925073, mean: -0.02930470381459963
std: 0.14424526018036718, min: -0.3303487530144711, max: 0.316569100653453

iteration: 4000, loss: -6.539374, current train MSE: 0.17354625291874032, lowers train MSE: 0.01673039869214983, training time: 283.1253s
model's performance on test data:
mse: 0.004685140487591338, rmse: 0.06844808607690457, mean: -0.027410041148902067
std: 0.06272338923488886, min: -0.2549864259165133, max: 0.06880480593488869

iteration: 6000, loss: -13.422905, current train MSE: 0.034982977306905194, lowers train MSE: 0.002168283187559779, training time: 431.6174s
model's performance on test data:
mse: 0.0011579175448750562, rmse: 0.03402818750499439, mean: 0.008141643381920303
std: 0.033041494558927, min: -0.08743040657443402, max: 0.06413805487846957

iteration: 8000, loss: -16.805164, current train MSE: 0.001448780413277639, lowers train MSE: 0.0008634581382256719, training time: 588.8714s
model's performance on test data:
mse: 0.0003249330777228431, rmse: 0.018025900191747515, mean: 0.0043243387921363605
std: 0.017500394232621935, min: -0.0555439304008587, max: 0.046267725136658555

iteration: 10000, loss: -19.080007, current train MSE: 0.0063766151013042, lowers train MSE: 0.000290569455377248, training time: 751.9513s
model's performance on test data:
mse: 6.830882719339036e-05, rmse: 0.00826491543776404, mean: 0.003272244295140579
std: 0.007589927878490527, min: -0.025786632624885897, max: 0.019788489525355946

iteration: 12000, loss: -19.855755, current train MSE: 0.00015781565930890693, lowers train MSE: 4.263827219844251e-05, training time: 924.2689s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 6.830882719339036e-05, rmse: 0.00826491543776404, mean: 0.003272244295140579
std: 0.007589927878490527, min: -0.025786632624885897, max: 0.019788489525355946

iteration: 14000, loss: -20.341754, current train MSE: 0.002213060652832574, lowers train MSE: 4.263827219844251e-05, training time: 1104.1271s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 6.830882719339036e-05, rmse: 0.00826491543776404, mean: 0.003272244295140579
std: 0.007589927878490527, min: -0.025786632624885897, max: 0.019788489525355946

iteration: 16000, loss: -20.426373, current train MSE: 0.00026641141353424643, lowers train MSE: 4.263827219844251e-05, training time: 1292.3232s
model's performance on test data:
mse: 6.830882719339036e-05, rmse: 0.00826491543776404, mean: 0.003272244295140579
std: 0.007589927878490527, min: -0.025786632624885897, max: 0.019788489525355946

iteration: 18000, loss: -20.447290, current train MSE: 0.00016366036720147101, lowers train MSE: 4.263827219844251e-05, training time: 1486.4449s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12087.434869096402, rmse: 109.94287093348255, mean: 78.5647786413714
std: 76.91295073197045, min: -14.258862147461935, max: 329.6462746417389

iteration: 0, loss: 6839.123965, current train MSE: 6838.629584570506, lowers train MSE: 6838.629584570506, training time: 1.2136s
model's performance on test data:
mse: 0.31787778299459835, rmse: 0.5638065120186165, mean: -0.05757360110317963
std: 0.5608872641878859, min: -1.1416982306884123, max: 3.2421200347507693

iteration: 2000, loss: -3.059535, current train MSE: 0.937827448165015, lowers train MSE: 0.36701953046052793, training time: 143.2858s
model's performance on test data:
mse: 0.02711949033155321, rmse: 0.16467996335788154, mean: -0.00836470759970718
std: 0.16447561289837512, min: -0.29482336110966045, max: 1.0329928186077382

iteration: 4000, loss: -5.799304, current train MSE: 0.16703249993014668, lowers train MSE: 0.01739838223349739, training time: 286.8471s
model's performance on test data:
mse: 0.0035189201530820384, rmse: 0.05932048679066987, mean: -0.01067207721693718
std: 0.05835552639079052, min: -0.1945632578605725, max: 0.10227390800397984

iteration: 6000, loss: -12.889257, current train MSE: 0.03755796616448012, lowers train MSE: 0.0023095734937728916, training time: 436.3131s
model's performance on test data:
mse: 0.0008633207094844622, rmse: 0.0293823196750097, mean: 0.010664745561038467
std: 0.027379899160100852, min: -0.08217820208219351, max: 0.059791429841155264

iteration: 8000, loss: -16.576515, current train MSE: 0.0022819427381821915, lowers train MSE: 0.0008146234594107714, training time: 594.7082s
model's performance on test data:
mse: 0.00036919338901475766, rmse: 0.0192144057679325, mean: -0.0013384096544839998
std: 0.01916869303651857, min: -0.08375346287846241, max: 0.030775810086237865

iteration: 10000, loss: -19.047760, current train MSE: 0.002194624142827178, lowers train MSE: 0.00013875054526955887, training time: 758.8401s
model's performance on test data:
mse: 6.850534962189263e-05, rmse: 0.008276795854791432, mean: 0.0027009357338397206
std: 0.007824092117460007, min: -0.020685975078094998, max: 0.018499519342682902

iteration: 12000, loss: -19.973716, current train MSE: 0.004063107687791039, lowers train MSE: 6.199346918221028e-05, training time: 931.0181s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 6.850534962189263e-05, rmse: 0.008276795854791432, mean: 0.0027009357338397206
std: 0.007824092117460007, min: -0.020685975078094998, max: 0.018499519342682902

iteration: 14000, loss: -20.519417, current train MSE: 0.006605109277009879, lowers train MSE: 6.199346918221028e-05, training time: 1111.4479s

##########
reduced lr to 1e-05
##########

model's performance on test data:
mse: 6.850534962189263e-05, rmse: 0.008276795854791432, mean: 0.0027009357338397206
std: 0.007824092117460007, min: -0.020685975078094998, max: 0.018499519342682902

iteration: 16000, loss: -20.591989, current train MSE: 0.00035600649899771085, lowers train MSE: 6.199346918221028e-05, training time: 1300.5483s
model's performance on test data:
mse: 6.850534962189263e-05, rmse: 0.008276795854791432, mean: 0.0027009357338397206
std: 0.007824092117460007, min: -0.020685975078094998, max: 0.018499519342682902

iteration: 18000, loss: -20.612428, current train MSE: 0.00027934872586383975, lowers train MSE: 6.199346918221028e-05, training time: 1496.5642s
Running on the GPU0

#### starting new seed ####

random seed is: 11135967900375438520
model's performance on test data:
mse: 12087.434869096402, rmse: 109.94287093348255, mean: 78.5647786413714
std: 76.91295073197045, min: -14.258862147461935, max: 329.6462746417389

iteration: 0, loss: 6845.545919, current train MSE: 6838.629584570506, lowers train MSE: 6838.629584570506, training time: 1.2191s
model's performance on test data:
mse: 0.20379736640346863, rmse: 0.45143921673185267, mean: -0.03784290377263583
std: 0.44987278172177203, min: -0.8738520052702441, max: 2.3436680297230623

iteration: 2000, loss: -0.150098, current train MSE: 0.28976215314370796, lowers train MSE: 0.28976215314370796, training time: 142.2488s
model's performance on test data:
mse: 0.01330618058687598, rmse: 0.11535241907682725, mean: -0.02162513061580545
std: 0.11331292205132389, min: -0.2535948340040477, max: 0.35725220053393514

iteration: 4000, loss: -3.695890, current train MSE: 0.049887710838746886, lowers train MSE: 0.00899893611703401, training time: 283.6306s
model's performance on test data:
mse: 0.006762995970251666, rmse: 0.08223743654961325, mean: -0.007044094530559413
std: 0.08193929528772438, min: -0.16305820523022163, max: 0.33111843349280434

iteration: 6000, loss: -7.621835, current train MSE: 0.0964637796650239, lowers train MSE: 0.004861910227634419, training time: 430.4736s
model's performance on test data:
mse: 0.004136281082240786, rmse: 0.06431392603659634, mean: 0.00638423775277755
std: 0.06399947020544784, min: -0.10876413563306642, max: 0.2980854249326512

iteration: 8000, loss: -11.456887, current train MSE: 0.02783917200364948, lowers train MSE: 0.002737549396383072, training time: 586.1224s
model's performance on test data:
mse: 0.0004648308436980297, rmse: 0.021559936078245447, mean: -0.00563196447187823
std: 0.02081237938428361, min: -0.07316779184303712, max: 0.05058481901919798

iteration: 10000, loss: -14.560857, current train MSE: 0.006654730647556888, lowers train MSE: 0.00031746811831148203, training time: 747.8498s
model's performance on test data:
mse: 0.00017179159359245356, rmse: 0.013106929220547944, mean: -0.007902910171458971
std: 0.010456889552856029, min: -0.058221485717410815, max: 0.014309376700895271

iteration: 12000, loss: -16.690904, current train MSE: 0.0016414999951682562, lowers train MSE: 0.00010923305149313413, training time: 918.2522s
model's performance on test data:
mse: 0.00011805454436596624, rmse: 0.010865290809084046, mean: -0.005955923447876242
std: 0.009087891904814993, min: -0.042632547234003226, max: 0.02023260670569016

iteration: 14000, loss: -18.726566, current train MSE: 0.003733661448107107, lowers train MSE: 6.954033446191204e-05, training time: 1097.6391s

##########
reduced lr to 0.0001
##########

model's performance on test data:
mse: 0.00011805454436596624, rmse: 0.010865290809084046, mean: -0.005955923447876242
std: 0.009087891904814993, min: -0.042632547234003226, max: 0.02023260670569016

iteration: 16000, loss: -20.012823, current train MSE: 0.00019503566534775953, lowers train MSE: 6.954033446191204e-05, training time: 1283.0873s
model's performance on test data:
mse: 8.524937911154378e-05, rmse: 0.009233059033253485, mean: -0.001363100928232374
std: 0.009132342251034709, min: -0.02502442312470521, max: 0.03712274142053218

iteration: 18000, loss: -20.125843, current train MSE: 0.032955615183462274, lowers train MSE: 5.002713099832062e-05, training time: 1476.1293s

##########
reduced lr to 1e-05
##########

